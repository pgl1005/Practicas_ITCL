{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "877f8a9f-f8ab-4e67-916c-3fc23e105c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b599f0-cfe6-4490-a0c2-d1b50bd8e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f47871c-b334-41d4-a6f4-a3339c28045c",
   "metadata": {},
   "source": [
    "### Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e36e505-9d37-409b-98a1-fbd8c847073c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
      "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
      "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
      "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
      "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
      "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
      "\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
      "0                  6                        25                    1   \n",
      "1                  1                         1                    7   \n",
      "2                  1                         1                    7   \n",
      "3                  1                         1                    7   \n",
      "4                  1                         1                    7   \n",
      "\n",
      "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
      "0                 1  ...          No      No                   No   \n",
      "1                 3  ...          No      Up                   No   \n",
      "2                 2  ...          No      No                   No   \n",
      "3                 2  ...          No      Up                   No   \n",
      "4                 1  ...          No  Steady                   No   \n",
      "\n",
      "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
      "0                   No                        No                       No   \n",
      "1                   No                        No                       No   \n",
      "2                   No                        No                       No   \n",
      "3                   No                        No                       No   \n",
      "4                   No                        No                       No   \n",
      "\n",
      "   metformin-pioglitazone  change diabetesMed readmitted  \n",
      "0                      No      No          No         NO  \n",
      "1                      No      Ch         Yes        >30  \n",
      "2                      No      No         Yes         NO  \n",
      "3                      No      Ch         Yes         NO  \n",
      "4                      No      Ch         Yes         NO  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             5346 non-null    object\n",
      " 23  A1Cresult                 17018 non-null   object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "encounter_id                    0\n",
      "patient_nbr                     0\n",
      "race                            0\n",
      "gender                          0\n",
      "age                             0\n",
      "weight                          0\n",
      "admission_type_id               0\n",
      "discharge_disposition_id        0\n",
      "admission_source_id             0\n",
      "time_in_hospital                0\n",
      "payer_code                      0\n",
      "medical_specialty               0\n",
      "num_lab_procedures              0\n",
      "num_procedures                  0\n",
      "num_medications                 0\n",
      "number_outpatient               0\n",
      "number_emergency                0\n",
      "number_inpatient                0\n",
      "diag_1                          0\n",
      "diag_2                          0\n",
      "diag_3                          0\n",
      "number_diagnoses                0\n",
      "max_glu_serum               96420\n",
      "A1Cresult                   84748\n",
      "metformin                       0\n",
      "repaglinide                     0\n",
      "nateglinide                     0\n",
      "chlorpropamide                  0\n",
      "glimepiride                     0\n",
      "acetohexamide                   0\n",
      "glipizide                       0\n",
      "glyburide                       0\n",
      "tolbutamide                     0\n",
      "pioglitazone                    0\n",
      "rosiglitazone                   0\n",
      "acarbose                        0\n",
      "miglitol                        0\n",
      "troglitazone                    0\n",
      "tolazamide                      0\n",
      "examide                         0\n",
      "citoglipton                     0\n",
      "insulin                         0\n",
      "glyburide-metformin             0\n",
      "glipizide-metformin             0\n",
      "glimepiride-pioglitazone        0\n",
      "metformin-rosiglitazone         0\n",
      "metformin-pioglitazone          0\n",
      "change                          0\n",
      "diabetesMed                     0\n",
      "readmitted                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "print(df.head())\n",
    "\n",
    "# Resumen de la información del dataset\n",
    "print(df.info())\n",
    "\n",
    "# Mostrar la cantidad de valores nulos por columna\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dd06818-b152-4e48-a181-97c92cf2c518",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_9000\\4281049621.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('diabetic_data.csv', na_values='?')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encounter_id                    0\n",
      "patient_nbr                     0\n",
      "race                         2273\n",
      "gender                          0\n",
      "age                             0\n",
      "weight                      98569\n",
      "admission_type_id               0\n",
      "discharge_disposition_id        0\n",
      "admission_source_id             0\n",
      "time_in_hospital                0\n",
      "payer_code                  40256\n",
      "medical_specialty           49949\n",
      "num_lab_procedures              0\n",
      "num_procedures                  0\n",
      "num_medications                 0\n",
      "number_outpatient               0\n",
      "number_emergency                0\n",
      "number_inpatient                0\n",
      "diag_1                         21\n",
      "diag_2                        358\n",
      "diag_3                       1423\n",
      "number_diagnoses                0\n",
      "max_glu_serum               96420\n",
      "A1Cresult                   84748\n",
      "metformin                       0\n",
      "repaglinide                     0\n",
      "nateglinide                     0\n",
      "chlorpropamide                  0\n",
      "glimepiride                     0\n",
      "acetohexamide                   0\n",
      "glipizide                       0\n",
      "glyburide                       0\n",
      "tolbutamide                     0\n",
      "pioglitazone                    0\n",
      "rosiglitazone                   0\n",
      "acarbose                        0\n",
      "miglitol                        0\n",
      "troglitazone                    0\n",
      "tolazamide                      0\n",
      "examide                         0\n",
      "citoglipton                     0\n",
      "insulin                         0\n",
      "glyburide-metformin             0\n",
      "glipizide-metformin             0\n",
      "glimepiride-pioglitazone        0\n",
      "metformin-rosiglitazone         0\n",
      "metformin-pioglitazone          0\n",
      "change                          0\n",
      "diabetesMed                     0\n",
      "readmitted                      0\n",
      "dtype: int64\n",
      "El archivo modificado ha sido guardado como 'diabetic_data_modified.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV, tratando '?' como valores nulos\n",
    "df = pd.read_csv('diabetic_data.csv', na_values='?')\n",
    "\n",
    "# Mostrar la cantidad de valores nulos por columna\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "df.to_csv('diabetic_data_modified.csv', index=False)\n",
    "\n",
    "print(\"El archivo modificado ha sido guardado como 'diabetic_data_modified.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7979e5ea-0c77-420d-a302-88729940fac7",
   "metadata": {},
   "source": [
    " ### Procesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b981c9ba-87b7-4d51-ab1c-3191da49f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_9000\\2766882862.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('diabetic_data_modified.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos procesados y guardados en 'processed_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('diabetic_data_modified.csv')\n",
    "\n",
    "# Asegurarse de manejar correctamente los valores nulos\n",
    "# Identificar las columnas con valores nulos según la descripción proporcionada\n",
    "cols_with_missing = ['race', 'weight', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "# Imputar los valores nulos con la moda para variables categóricas\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cols_with_missing] = categorical_imputer.fit_transform(df[cols_with_missing])\n",
    "\n",
    "# Limpiar y convertir 'weight' a valores numéricos y luego categorizarlo\n",
    "def clean_weight(weight_str):\n",
    "    if weight_str == \"?\":\n",
    "        return None\n",
    "    elif weight_str.startswith(\">\"):\n",
    "        return float(weight_str[1:]) + 1  # Incrementar en 1 para asegurar que los límites sean correctos\n",
    "    elif weight_str.startswith(\"[\"):\n",
    "        return float(weight_str.strip(\"[]\").split(\"-\")[0])\n",
    "    elif weight_str == \"Unknown\":\n",
    "        return None\n",
    "    else:\n",
    "        return float(weight_str)\n",
    "\n",
    "df['weight'] = df['weight'].apply(clean_weight)\n",
    "\n",
    "# Definir los rangos de peso y codificar 'weight'\n",
    "weight_ranges = ['[0-25)', '[25-50)', '[50-75)', '[75-100)', '[100-125)', '[125-150)', '[150-175)', '[175-200)', '>200']\n",
    "df['weight_category'] = pd.cut(df['weight'], bins=[0, 25, 50, 75, 100, 125, 150, 175, 200, float('inf')], labels=weight_ranges, right=False)\n",
    "\n",
    "# Eliminar la columna original 'weight'\n",
    "df.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "# Función para asignar categorías a los códigos ICD-9\n",
    "def assign_icd_category(icd_code):\n",
    "    if pd.isnull(icd_code):\n",
    "        return 'Unknown'\n",
    "    if icd_code.startswith(('E', 'V')):\n",
    "        return 'E-V codes'\n",
    "    else:\n",
    "        code_number = int(icd_code.split('.')[0])  # Tomar solo el número de código ICD-9\n",
    "        if 1 <= code_number <= 139:\n",
    "            return '001-139'\n",
    "        elif 140 <= code_number <= 239:\n",
    "            return '140-239'\n",
    "        elif 240 <= code_number <= 279:\n",
    "            return '240-279'\n",
    "        elif 280 <= code_number <= 289:\n",
    "            return '280-289'\n",
    "        elif 290 <= code_number <= 319:\n",
    "            return '290-319'\n",
    "        elif 320 <= code_number <= 389:\n",
    "            return '320-389'\n",
    "        elif 390 <= code_number <= 459:\n",
    "            return '390-459'\n",
    "        elif 460 <= code_number <= 519:\n",
    "            return '460-519'\n",
    "        elif 520 <= code_number <= 579:\n",
    "            return '520-579'\n",
    "        elif 580 <= code_number <= 629:\n",
    "            return '580-629'\n",
    "        elif 630 <= code_number <= 679:\n",
    "            return '630-679'\n",
    "        elif 680 <= code_number <= 709:\n",
    "            return '680-709'\n",
    "        elif 710 <= code_number <= 739:\n",
    "            return '710-739'\n",
    "        elif 740 <= code_number <= 759:\n",
    "            return '740-759'\n",
    "        elif 760 <= code_number <= 779:\n",
    "            return '760-779'\n",
    "        elif 780 <= code_number <= 799:\n",
    "            return '780-799'\n",
    "        elif 800 <= code_number <= 999:\n",
    "            return '800-999'\n",
    "        else:\n",
    "            return 'Other'  # En caso de no encontrar una categoría válida\n",
    "\n",
    "# Aplicar la función a cada columna de diagnóstico\n",
    "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    df[col + '_category'] = df[col].apply(assign_icd_category)\n",
    "\n",
    "# Eliminar las columnas originales de diagnóstico\n",
    "df.drop(columns=['diag_1', 'diag_2', 'diag_3'], inplace=True)\n",
    "\n",
    "# Función para asignar valores únicos a las franjas de edad\n",
    "def age_to_value(age_str):\n",
    "    age_mapping = {\n",
    "        '[0-10)': 5,\n",
    "        '[10-20)': 15,\n",
    "        '[20-30)': 25,\n",
    "        '[30-40)': 35,\n",
    "        '[40-50)': 45,\n",
    "        '[50-60)': 55,\n",
    "        '[60-70)': 65,\n",
    "        '[70-80)': 75,\n",
    "        '[80-90)': 85,\n",
    "        '[90-100)': 95\n",
    "    }\n",
    "    return age_mapping.get(age_str, None)\n",
    "\n",
    "# Aplicar la función de agrupamiento de edades\n",
    "df['age'] = df['age'].apply(age_to_value)\n",
    "\n",
    "# Aplicar codificación one-hot a las variables categóricas, excluyendo 'age' ya que está mapeada a valores únicos\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'age' in categorical_cols:\n",
    "    categorical_cols.remove('age')\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(df[categorical_cols]))\n",
    "\n",
    "# Sustituir las columnas originales con las nuevas codificadas\n",
    "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "df.drop(columns=categorical_cols, inplace=True)\n",
    "df = pd.concat([df, encoded_cols], axis=1)\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "# df.to_csv('processed_data.csv', index=False)\n",
    "\n",
    "print(\"Datos procesados y guardados en 'processed_data.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8857d681-30ff-4780-800e-4168169f6bfb",
   "metadata": {},
   "source": [
    "Para implementar un árbol de decisión en PyTorch, tendrás que crear una red neuronal que emule el comportamiento de un árbol de decisión, ya que PyTorch está orientado a redes neuronales y no proporciona una implementación directa de árboles de decisión. Sin embargo, se puede simular el comportamiento de un árbol de decisión mediante una red neuronal con capas especializadas que emulen las decisiones binarias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bc2ea4-62af-41ca-8932-741918b8d4c5",
   "metadata": {},
   "source": [
    "### Creación del modelo de árbol de decisión con Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63753291-4938-44ed-8867-3e277e553eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Accuracy del modelo local en validación: 0.73230\n",
      "Epoch 2/10, Accuracy del modelo local en validación: 0.98608\n",
      "Epoch 3/10, Accuracy del modelo local en validación: 0.99918\n",
      "Epoch 4/10, Accuracy del modelo local en validación: 0.99959\n",
      "Epoch 5/10, Accuracy del modelo local en validación: 0.99959\n",
      "Epoch 6/10, Accuracy del modelo local en validación: 0.99959\n",
      "Epoch 7/10, Accuracy del modelo local en validación: 1.00000\n",
      "Epoch 8/10, Accuracy del modelo local en validación: 1.00000\n",
      "Epoch 9/10, Accuracy del modelo local en validación: 1.00000\n",
      "Epoch 10/10, Accuracy del modelo local en validación: 1.00000\n",
      "Accuracy del modelo local en el dispositivo 1: 0.99889\n",
      "\n",
      "Epoch 1/10, Accuracy del modelo local en validación: 0.75808\n",
      "Epoch 2/10, Accuracy del modelo local en validación: 0.94228\n",
      "Epoch 3/10, Accuracy del modelo local en validación: 0.99386\n",
      "Epoch 4/10, Accuracy del modelo local en validación: 0.99673\n",
      "Epoch 5/10, Accuracy del modelo local en validación: 0.99754\n",
      "Epoch 6/10, Accuracy del modelo local en validación: 0.99795\n",
      "Epoch 7/10, Accuracy del modelo local en validación: 0.99795\n",
      "Epoch 8/10, Accuracy del modelo local en validación: 0.99795\n",
      "Epoch 9/10, Accuracy del modelo local en validación: 0.99795\n",
      "Epoch 10/10, Accuracy del modelo local en validación: 0.99795\n",
      "Accuracy del modelo local en el dispositivo 2: 0.99889\n",
      "\n",
      "Epoch 1/10, Accuracy del modelo local en validación: 0.75972\n",
      "Epoch 2/10, Accuracy del modelo local en validación: 0.75972\n",
      "Epoch 3/10, Accuracy del modelo local en validación: 0.98813\n",
      "Epoch 4/10, Accuracy del modelo local en validación: 0.99673\n",
      "Epoch 5/10, Accuracy del modelo local en validación: 0.99713\n",
      "Epoch 6/10, Accuracy del modelo local en validación: 0.99754\n",
      "Epoch 7/10, Accuracy del modelo local en validación: 0.99754\n",
      "Epoch 8/10, Accuracy del modelo local en validación: 0.99754\n",
      "Epoch 9/10, Accuracy del modelo local en validación: 0.99673\n",
      "Epoch 10/10, Accuracy del modelo local en validación: 0.99754\n",
      "Accuracy del modelo local en el dispositivo 3: 0.99853\n",
      "\n",
      "Epoch 1/10, Accuracy del modelo local en validación: 0.80516\n",
      "Epoch 2/10, Accuracy del modelo local en validación: 0.80516\n",
      "Epoch 3/10, Accuracy del modelo local en validación: 0.99304\n",
      "Epoch 4/10, Accuracy del modelo local en validación: 0.99795\n",
      "Epoch 5/10, Accuracy del modelo local en validación: 0.99795\n",
      "Epoch 6/10, Accuracy del modelo local en validación: 0.99836\n",
      "Epoch 7/10, Accuracy del modelo local en validación: 0.99836\n",
      "Epoch 8/10, Accuracy del modelo local en validación: 0.99877\n",
      "Epoch 9/10, Accuracy del modelo local en validación: 0.99836\n",
      "Epoch 10/10, Accuracy del modelo local en validación: 0.99836\n",
      "Accuracy del modelo local en el dispositivo 4: 0.99889\n",
      "\n",
      "Epoch 1/10, Accuracy del modelo local en validación: 0.79451\n",
      "Epoch 2/10, Accuracy del modelo local en validación: 0.79492\n",
      "Epoch 3/10, Accuracy del modelo local en validación: 0.99059\n",
      "Epoch 4/10, Accuracy del modelo local en validación: 0.99713\n",
      "Epoch 5/10, Accuracy del modelo local en validación: 0.99877\n",
      "Epoch 6/10, Accuracy del modelo local en validación: 0.99877\n",
      "Epoch 7/10, Accuracy del modelo local en validación: 0.99795\n",
      "Epoch 8/10, Accuracy del modelo local en validación: 0.99877\n",
      "Epoch 9/10, Accuracy del modelo local en validación: 0.99877\n",
      "Epoch 10/10, Accuracy del modelo local en validación: 0.99836\n",
      "Accuracy del modelo local en el dispositivo 5: 0.99840\n",
      "\n",
      "Accuracy del modelo global en datos combinados de prueba: 0.77003\n",
      "Accuracy del modelo global después de una iteración: 0.99872\n",
      "Accuracy del modelo global en datos combinados de prueba: 0.77003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Función para cargar los datos\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# Función para dividir los datos en partes para simular diferentes dispositivos\n",
    "def split_data(X, y, num_parts):\n",
    "    X_splits = np.array_split(X, num_parts)\n",
    "    y_splits = np.array_split(y, num_parts)\n",
    "    return X_splits, y_splits\n",
    "\n",
    "# Definir la red neuronal que simula un árbol de decisión\n",
    "class DecisionTreeNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DecisionTreeNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc5 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.sigmoid(self.fc5(x))\n",
    "        return x\n",
    "\n",
    "# Función para entrenar el modelo en un dispositivo\n",
    "def train_on_device(X_train, y_train, X_val, y_val, model, epochs=10, lr=0.0001, weight_decay=1e-4, batch_size=64):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "    X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "    y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    dataset = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Evaluar el modelo local en datos de validación del dispositivo\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = model(X_val_tensor)\n",
    "            predicted = (outputs.numpy() > 0.5).astype(int)\n",
    "            val_accuracy = accuracy_score(y_val_tensor.numpy(), predicted)\n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Accuracy del modelo local en validación: {val_accuracy:.5f}')\n",
    "    \n",
    "    return model, val_accuracy\n",
    "\n",
    "# Función principal para la simulación de Federated Learning\n",
    "def federated_learning(X, y, num_parts, epochs=10, lr=0.0001, weight_decay=1e-4, batch_size=64):\n",
    "    X_splits, y_splits = split_data(X, y, num_parts)\n",
    "    local_models = []\n",
    "    scalers = []\n",
    "    local_accuracies = []\n",
    "    global_accuracy = 0.0\n",
    "\n",
    "    for i in range(num_parts):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_splits[i], y_splits[i], test_size=0.4, stratify=y_splits[i])\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, stratify=y_train)  # Dividir datos de entrenamiento en entrenamiento y validación\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        local_model = DecisionTreeNN(X_train_scaled.shape[1])\n",
    "        local_model, val_accuracy = train_on_device(X_train_scaled, y_train, X_val_scaled, y_val, local_model, epochs=epochs, lr=lr, weight_decay=weight_decay, batch_size=batch_size)\n",
    "        local_models.append(local_model)\n",
    "        scalers.append(scaler)\n",
    "        \n",
    "        # Evaluar el modelo local en datos de prueba del dispositivo\n",
    "        X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "        y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "        \n",
    "        local_model.eval()\n",
    "        with torch.no_grad():\n",
    "            outputs = local_model(X_test_tensor)\n",
    "            predicted = (outputs.numpy() > 0.5).astype(int)\n",
    "            local_accuracy = accuracy_score(y_test_tensor.numpy(), predicted)\n",
    "            local_accuracies.append(local_accuracy)\n",
    "            print(f'Accuracy del modelo local en el dispositivo {i + 1}: {local_accuracy:.5f}')\n",
    "            print()\n",
    "    \n",
    "    # Calcular el accuracy global como el promedio de los accuracies locales\n",
    "    global_accuracy = sum(local_accuracies) / num_parts\n",
    "    \n",
    "    # Evaluar el modelo global en datos combinados de prueba\n",
    "    X_combined_scaled = np.vstack([scalers[i].transform(X_splits[i]) for i in range(num_parts)])\n",
    "    y_combined = np.hstack([y_splits[i] for i in range(num_parts)])\n",
    "    \n",
    "    X_combined_tensor = torch.tensor(X_combined_scaled, dtype=torch.float32)\n",
    "    y_combined_tensor = torch.tensor(y_combined, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    global_model = DecisionTreeNN(X.shape[1])\n",
    "    global_state_dict = global_model.state_dict()\n",
    "    \n",
    "    for key in global_state_dict.keys():\n",
    "        global_state_dict[key] = torch.mean(torch.stack([model.state_dict()[key].float() for model in local_models]), dim=0)\n",
    "    \n",
    "    global_model.load_state_dict(global_state_dict)\n",
    "    \n",
    "    global_model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = global_model(X_combined_tensor)\n",
    "        predicted = (outputs.numpy() > 0.5).astype(int)\n",
    "        global_accuracy_combined = accuracy_score(y_combined_tensor.numpy(), predicted)\n",
    "        print(f'Accuracy del modelo global en datos combinados de prueba: {global_accuracy_combined:.5f}')\n",
    "    \n",
    "    return global_accuracy, global_accuracy_combined\n",
    "\n",
    "# Número de partes para simular diferentes dispositivos\n",
    "num_parts = 5\n",
    "\n",
    "# Cargar datos desde el archivo CSV\n",
    "df = load_data('processed_data.csv')\n",
    "\n",
    "# Seleccionar características y etiquetas\n",
    "X = df.drop(columns=['diabetesMed_Yes'])\n",
    "y = df['diabetesMed_Yes']\n",
    "\n",
    "# Ejecutar una sola iteración de federated learning\n",
    "global_accuracy, global_accuracy_combined = federated_learning(X, y, num_parts)\n",
    "\n",
    "# Imprimir el accuracy global después de una iteración\n",
    "print(f'Accuracy del modelo global después de una iteración: {global_accuracy:.5f}')\n",
    "\n",
    "# Imprimir el accuracy del modelo global en datos combinados de prueba\n",
    "print(f'Accuracy del modelo global en datos combinados de prueba: {global_accuracy_combined:.5f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef58182d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5b4e71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_virtual",
   "language": "python",
   "name": "entorno_virtual"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
