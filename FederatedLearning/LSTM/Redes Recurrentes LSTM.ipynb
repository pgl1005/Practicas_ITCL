{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9597173",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abceb3c3",
   "metadata": {},
   "source": [
    "### Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a371cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
      "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
      "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
      "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
      "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
      "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
      "\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
      "0                  6                        25                    1   \n",
      "1                  1                         1                    7   \n",
      "2                  1                         1                    7   \n",
      "3                  1                         1                    7   \n",
      "4                  1                         1                    7   \n",
      "\n",
      "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
      "0                 1  ...          No      No                   No   \n",
      "1                 3  ...          No      Up                   No   \n",
      "2                 2  ...          No      No                   No   \n",
      "3                 2  ...          No      Up                   No   \n",
      "4                 1  ...          No  Steady                   No   \n",
      "\n",
      "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
      "0                   No                        No                       No   \n",
      "1                   No                        No                       No   \n",
      "2                   No                        No                       No   \n",
      "3                   No                        No                       No   \n",
      "4                   No                        No                       No   \n",
      "\n",
      "   metformin-pioglitazone  change diabetesMed readmitted  \n",
      "0                      No      No          No         NO  \n",
      "1                      No      Ch         Yes        >30  \n",
      "2                      No      No         Yes         NO  \n",
      "3                      No      Ch         Yes         NO  \n",
      "4                      No      Ch         Yes         NO  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             101766 non-null  object\n",
      " 23  A1Cresult                 101766 non-null  object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "encounter_id                0\n",
      "patient_nbr                 0\n",
      "race                        0\n",
      "gender                      0\n",
      "age                         0\n",
      "weight                      0\n",
      "admission_type_id           0\n",
      "discharge_disposition_id    0\n",
      "admission_source_id         0\n",
      "time_in_hospital            0\n",
      "payer_code                  0\n",
      "medical_specialty           0\n",
      "num_lab_procedures          0\n",
      "num_procedures              0\n",
      "num_medications             0\n",
      "number_outpatient           0\n",
      "number_emergency            0\n",
      "number_inpatient            0\n",
      "diag_1                      0\n",
      "diag_2                      0\n",
      "diag_3                      0\n",
      "number_diagnoses            0\n",
      "max_glu_serum               0\n",
      "A1Cresult                   0\n",
      "metformin                   0\n",
      "repaglinide                 0\n",
      "nateglinide                 0\n",
      "chlorpropamide              0\n",
      "glimepiride                 0\n",
      "acetohexamide               0\n",
      "glipizide                   0\n",
      "glyburide                   0\n",
      "tolbutamide                 0\n",
      "pioglitazone                0\n",
      "rosiglitazone               0\n",
      "acarbose                    0\n",
      "miglitol                    0\n",
      "troglitazone                0\n",
      "tolazamide                  0\n",
      "examide                     0\n",
      "citoglipton                 0\n",
      "insulin                     0\n",
      "glyburide-metformin         0\n",
      "glipizide-metformin         0\n",
      "glimepiride-pioglitazone    0\n",
      "metformin-rosiglitazone     0\n",
      "metformin-pioglitazone      0\n",
      "change                      0\n",
      "diabetesMed                 0\n",
      "readmitted                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "print(df.head())\n",
    "\n",
    "# Resumen de la información del dataset\n",
    "print(df.info())\n",
    "\n",
    "# Mostrar la cantidad de valores nulos por columna\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed6366c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_16120\\4281049621.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('diabetic_data.csv', na_values='?')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encounter_id                    0\n",
      "patient_nbr                     0\n",
      "race                         2273\n",
      "gender                          0\n",
      "age                             0\n",
      "weight                      98569\n",
      "admission_type_id               0\n",
      "discharge_disposition_id        0\n",
      "admission_source_id             0\n",
      "time_in_hospital                0\n",
      "payer_code                  40256\n",
      "medical_specialty           49949\n",
      "num_lab_procedures              0\n",
      "num_procedures                  0\n",
      "num_medications                 0\n",
      "number_outpatient               0\n",
      "number_emergency                0\n",
      "number_inpatient                0\n",
      "diag_1                         21\n",
      "diag_2                        358\n",
      "diag_3                       1423\n",
      "number_diagnoses                0\n",
      "max_glu_serum                   0\n",
      "A1Cresult                       0\n",
      "metformin                       0\n",
      "repaglinide                     0\n",
      "nateglinide                     0\n",
      "chlorpropamide                  0\n",
      "glimepiride                     0\n",
      "acetohexamide                   0\n",
      "glipizide                       0\n",
      "glyburide                       0\n",
      "tolbutamide                     0\n",
      "pioglitazone                    0\n",
      "rosiglitazone                   0\n",
      "acarbose                        0\n",
      "miglitol                        0\n",
      "troglitazone                    0\n",
      "tolazamide                      0\n",
      "examide                         0\n",
      "citoglipton                     0\n",
      "insulin                         0\n",
      "glyburide-metformin             0\n",
      "glipizide-metformin             0\n",
      "glimepiride-pioglitazone        0\n",
      "metformin-rosiglitazone         0\n",
      "metformin-pioglitazone          0\n",
      "change                          0\n",
      "diabetesMed                     0\n",
      "readmitted                      0\n",
      "dtype: int64\n",
      "El archivo modificado ha sido guardado como 'diabetic_data_modified.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV, tratando '?' como valores nulos\n",
    "df = pd.read_csv('diabetic_data.csv', na_values='?')\n",
    "\n",
    "# Mostrar la cantidad de valores nulos por columna\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "df.to_csv('diabetic_data_modified.csv', index=False)\n",
    "\n",
    "print(\"El archivo modificado ha sido guardado como 'diabetic_data_modified.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c408f63",
   "metadata": {},
   "source": [
    "### Procesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77d085a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_16120\\2766882862.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('diabetic_data_modified.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos procesados y guardados en 'processed_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('diabetic_data_modified.csv')\n",
    "\n",
    "# Asegurarse de manejar correctamente los valores nulos\n",
    "# Identificar las columnas con valores nulos según la descripción proporcionada\n",
    "cols_with_missing = ['race', 'weight', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "# Imputar los valores nulos con la moda para variables categóricas\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cols_with_missing] = categorical_imputer.fit_transform(df[cols_with_missing])\n",
    "\n",
    "# Limpiar y convertir 'weight' a valores numéricos y luego categorizarlo\n",
    "def clean_weight(weight_str):\n",
    "    if weight_str == \"?\":\n",
    "        return None\n",
    "    elif weight_str.startswith(\">\"):\n",
    "        return float(weight_str[1:]) + 1  # Incrementar en 1 para asegurar que los límites sean correctos\n",
    "    elif weight_str.startswith(\"[\"):\n",
    "        return float(weight_str.strip(\"[]\").split(\"-\")[0])\n",
    "    elif weight_str == \"Unknown\":\n",
    "        return None\n",
    "    else:\n",
    "        return float(weight_str)\n",
    "\n",
    "df['weight'] = df['weight'].apply(clean_weight)\n",
    "\n",
    "# Definir los rangos de peso y codificar 'weight'\n",
    "weight_ranges = ['[0-25)', '[25-50)', '[50-75)', '[75-100)', '[100-125)', '[125-150)', '[150-175)', '[175-200)', '>200']\n",
    "df['weight_category'] = pd.cut(df['weight'], bins=[0, 25, 50, 75, 100, 125, 150, 175, 200, float('inf')], labels=weight_ranges, right=False)\n",
    "\n",
    "# Eliminar la columna original 'weight'\n",
    "df.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "# Función para asignar categorías a los códigos ICD-9\n",
    "def assign_icd_category(icd_code):\n",
    "    if pd.isnull(icd_code):\n",
    "        return 'Unknown'\n",
    "    if icd_code.startswith(('E', 'V')):\n",
    "        return 'E-V codes'\n",
    "    else:\n",
    "        code_number = int(icd_code.split('.')[0])  # Tomar solo el número de código ICD-9\n",
    "        if 1 <= code_number <= 139:\n",
    "            return '001-139'\n",
    "        elif 140 <= code_number <= 239:\n",
    "            return '140-239'\n",
    "        elif 240 <= code_number <= 279:\n",
    "            return '240-279'\n",
    "        elif 280 <= code_number <= 289:\n",
    "            return '280-289'\n",
    "        elif 290 <= code_number <= 319:\n",
    "            return '290-319'\n",
    "        elif 320 <= code_number <= 389:\n",
    "            return '320-389'\n",
    "        elif 390 <= code_number <= 459:\n",
    "            return '390-459'\n",
    "        elif 460 <= code_number <= 519:\n",
    "            return '460-519'\n",
    "        elif 520 <= code_number <= 579:\n",
    "            return '520-579'\n",
    "        elif 580 <= code_number <= 629:\n",
    "            return '580-629'\n",
    "        elif 630 <= code_number <= 679:\n",
    "            return '630-679'\n",
    "        elif 680 <= code_number <= 709:\n",
    "            return '680-709'\n",
    "        elif 710 <= code_number <= 739:\n",
    "            return '710-739'\n",
    "        elif 740 <= code_number <= 759:\n",
    "            return '740-759'\n",
    "        elif 760 <= code_number <= 779:\n",
    "            return '760-779'\n",
    "        elif 780 <= code_number <= 799:\n",
    "            return '780-799'\n",
    "        elif 800 <= code_number <= 999:\n",
    "            return '800-999'\n",
    "        else:\n",
    "            return 'Other'  # En caso de no encontrar una categoría válida\n",
    "\n",
    "# Aplicar la función a cada columna de diagnóstico\n",
    "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    df[col + '_category'] = df[col].apply(assign_icd_category)\n",
    "\n",
    "# Eliminar las columnas originales de diagnóstico\n",
    "df.drop(columns=['diag_1', 'diag_2', 'diag_3'], inplace=True)\n",
    "\n",
    "# Función para asignar valores únicos a las franjas de edad\n",
    "def age_to_value(age_str):\n",
    "    age_mapping = {\n",
    "        '[0-10)': 5,\n",
    "        '[10-20)': 15,\n",
    "        '[20-30)': 25,\n",
    "        '[30-40)': 35,\n",
    "        '[40-50)': 45,\n",
    "        '[50-60)': 55,\n",
    "        '[60-70)': 65,\n",
    "        '[70-80)': 75,\n",
    "        '[80-90)': 85,\n",
    "        '[90-100)': 95\n",
    "    }\n",
    "    return age_mapping.get(age_str, None)\n",
    "\n",
    "# Aplicar la función de agrupamiento de edades\n",
    "df['age'] = df['age'].apply(age_to_value)\n",
    "\n",
    "# Aplicar codificación one-hot a las variables categóricas, excluyendo 'age' ya que está mapeada a valores únicos\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'age' in categorical_cols:\n",
    "    categorical_cols.remove('age')\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(df[categorical_cols]))\n",
    "\n",
    "# Sustituir las columnas originales con las nuevas codificadas\n",
    "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "df.drop(columns=categorical_cols, inplace=True)\n",
    "df = pd.concat([df, encoded_cols], axis=1)\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "# df.to_csv('processed_data.csv', index=False)\n",
    "\n",
    "print(\"Datos procesados y guardados en 'processed_data.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b15ba1",
   "metadata": {},
   "source": [
    "### Creación del modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef32f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1/1\n",
      "Entrenando modelo local 1/5\n",
      "Tamaño de X_train_scaled: (12212, 213, 1)\n",
      "Tamaño de y_train: (12212,)\n",
      "Epoch 1/5\n",
      "306/306 [==============================] - 126s 364ms/step - loss: 0.9982 - accuracy: 0.6373 - val_loss: 0.7406 - val_accuracy: 0.7266\n",
      "Epoch 2/5\n",
      "306/306 [==============================] - 111s 363ms/step - loss: 0.7033 - accuracy: 0.7141 - val_loss: 0.6468 - val_accuracy: 0.7266\n",
      "Epoch 3/5\n",
      "306/306 [==============================] - 112s 365ms/step - loss: 0.6311 - accuracy: 0.7329 - val_loss: 0.6155 - val_accuracy: 0.7266\n",
      "Epoch 4/5\n",
      "306/306 [==============================] - 111s 364ms/step - loss: 0.6044 - accuracy: 0.7340 - val_loss: 0.6051 - val_accuracy: 0.7266\n",
      "Epoch 5/5\n",
      "306/306 [==============================] - 109s 356ms/step - loss: 0.5945 - accuracy: 0.7340 - val_loss: 0.6095 - val_accuracy: 0.7266\n",
      "Entrenando modelo local 2/5\n",
      "Tamaño de X_train_scaled: (12211, 213, 1)\n",
      "Tamaño de y_train: (12211,)\n",
      "Epoch 1/5\n",
      "306/306 [==============================] - 125s 365ms/step - loss: 1.0435 - accuracy: 0.6477 - val_loss: 0.7676 - val_accuracy: 0.7503\n",
      "Epoch 2/5\n",
      "306/306 [==============================] - 109s 355ms/step - loss: 0.7151 - accuracy: 0.7374 - val_loss: 0.6526 - val_accuracy: 0.7503\n",
      "Epoch 3/5\n",
      "306/306 [==============================] - 107s 351ms/step - loss: 0.6309 - accuracy: 0.7507 - val_loss: 0.6120 - val_accuracy: 0.7503\n",
      "Epoch 4/5\n",
      "306/306 [==============================] - 107s 350ms/step - loss: 0.5871 - accuracy: 0.7572 - val_loss: 0.6087 - val_accuracy: 0.7503\n",
      "Epoch 5/5\n",
      "306/306 [==============================] - 106s 348ms/step - loss: 0.5700 - accuracy: 0.7599 - val_loss: 0.5791 - val_accuracy: 0.7503\n",
      "Entrenando modelo local 3/5\n",
      "Tamaño de X_train_scaled: (12211, 213, 1)\n",
      "Tamaño de y_train: (12211,)\n",
      "Epoch 1/5\n",
      "306/306 [==============================] - 124s 360ms/step - loss: 0.9919 - accuracy: 0.6575 - val_loss: 0.7165 - val_accuracy: 0.7544\n",
      "Epoch 2/5\n",
      "306/306 [==============================] - 106s 345ms/step - loss: 0.6807 - accuracy: 0.7430 - val_loss: 0.6193 - val_accuracy: 0.7544\n",
      "Epoch 3/5\n",
      "306/306 [==============================] - 106s 346ms/step - loss: 0.6105 - accuracy: 0.7531 - val_loss: 0.5868 - val_accuracy: 0.7544\n",
      "Epoch 4/5\n",
      "306/306 [==============================] - 106s 347ms/step - loss: 0.5793 - accuracy: 0.7570 - val_loss: 0.5739 - val_accuracy: 0.7536\n",
      "Epoch 5/5\n",
      "306/306 [==============================] - 107s 348ms/step - loss: 0.5705 - accuracy: 0.7577 - val_loss: 0.5644 - val_accuracy: 0.7544\n",
      "Entrenando modelo local 4/5\n",
      "Tamaño de X_train_scaled: (12211, 213, 1)\n",
      "Tamaño de y_train: (12211,)\n",
      "Epoch 1/5\n",
      "306/306 [==============================] - 124s 362ms/step - loss: 0.9834 - accuracy: 0.6784 - val_loss: 0.6961 - val_accuracy: 0.8019\n",
      "Epoch 2/5\n",
      "306/306 [==============================] - 113s 370ms/step - loss: 0.6522 - accuracy: 0.7888 - val_loss: 0.5781 - val_accuracy: 0.8019\n",
      "Epoch 3/5\n",
      "128/306 [===========>..................] - ETA: 1:01 - loss: 0.5667 - accuracy: 0.8118"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "# Función fijar semillas (para reproducibilidad de los resultados)\n",
    "def fijar_semillas():\n",
    "    set_seed(123)\n",
    "    np.random.seed(123)\n",
    "    random.seed(123)\n",
    "    torch.manual_seed(123)\n",
    "\n",
    "# Función para cargar los datos\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# Función para dividir los datos en partes para simular diferentes dispositivos\n",
    "def split_data(X, y, num_parts):\n",
    "    X_splits = np.array_split(X, num_parts)\n",
    "    y_splits = np.array_split(y, num_parts)\n",
    "    return X_splits, y_splits\n",
    "\n",
    "# Función para crear un modelo LSTM\n",
    "def crear_modelo_lstm(input_shape):\n",
    "    entrada = Input(shape=input_shape)\n",
    "    lstm_out = LSTM(50, return_sequences=True, kernel_regularizer=l2(0.01))(entrada)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "    lstm_out = Dropout(0.3)(lstm_out)\n",
    "    lstm_out = LSTM(20, kernel_regularizer=l2(0.01))(lstm_out)\n",
    "    lstm_out = BatchNormalization()(lstm_out)\n",
    "    lstm_out = Dropout(0.3)(lstm_out)\n",
    "    salida = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))(lstm_out)\n",
    "    modelo = Model(inputs=entrada, outputs=salida)\n",
    "    modelo.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return modelo\n",
    "\n",
    "# Función para entrenar el modelo en un dispositivo\n",
    "def train_on_device(X_train, y_train, input_shape, epochs=5, lr=0.001):\n",
    "    modelo = crear_modelo_lstm(input_shape)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    modelo.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_split=0.2, callbacks=[early_stopping], verbose=1)\n",
    "    return modelo\n",
    "\n",
    "# Función principal para la simulación de Federated Learning\n",
    "def federated_learning(X, y, num_parts, num_iterations, epochs=5, lr=0.001):\n",
    "    all_accuracies = []\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f'Iteración {iteration + 1}/{num_iterations}')\n",
    "        X_splits, y_splits = split_data(X, y, num_parts)\n",
    "        local_models = []\n",
    "        scalers = []\n",
    "\n",
    "        for i in range(num_parts):\n",
    "            print(f'Entrenando modelo local {i + 1}/{num_parts}')\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X_splits[i], y_splits[i], test_size=0.4, random_state=iteration, stratify=y_splits[i])\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train).reshape(-1, X_train.shape[1], 1)\n",
    "            X_test_scaled = scaler.transform(X_test).reshape(-1, X_test.shape[1], 1)\n",
    "            \n",
    "            print(f'Tamaño de X_train_scaled: {X_train_scaled.shape}')\n",
    "            print(f'Tamaño de y_train: {y_train.shape}')\n",
    "            \n",
    "            local_model = train_on_device(X_train_scaled, y_train, input_shape=(X_train.shape[1], 1), epochs=epochs, lr=lr)\n",
    "            local_models.append(local_model)\n",
    "            scalers.append(scaler)\n",
    "        \n",
    "        # Crear el modelo global combinando los modelos locales\n",
    "        print('Creando modelo global')\n",
    "        global_model = crear_modelo_lstm(input_shape=(X.shape[1], 1))\n",
    "        global_weights = np.mean([model.get_weights() for model in local_models], axis=0)\n",
    "        global_model.set_weights(global_weights)\n",
    "        \n",
    "        # Evaluar el modelo global en datos de prueba combinados\n",
    "        X_test_combined = np.vstack([scalers[i].transform(X_splits[i]).reshape(-1, X_splits[i].shape[1], 1) for i in range(num_parts)])\n",
    "        y_test_combined = np.hstack([y_splits[i] for i in range(num_parts)])\n",
    "        \n",
    "        loss, accuracy = global_model.evaluate(X_test_combined, y_test_combined, verbose=0)\n",
    "        \n",
    "        all_accuracies.append(accuracy)\n",
    "        print(f'Accuracy del modelo global después de {iteration + 1} iteración: {accuracy:.5f}\\n')\n",
    "    \n",
    "    return all_accuracies\n",
    "\n",
    "# Número de iteraciones\n",
    "num_iterations = 1\n",
    "\n",
    "# Cargar datos desde el archivo CSV\n",
    "df = load_data('processed_data.csv')\n",
    "\n",
    "# Seleccionar características y etiquetas\n",
    "X = df.drop(columns=['diabetesMed_Yes']).values\n",
    "y = df['diabetesMed_Yes'].values\n",
    "\n",
    "# Número de partes para simular diferentes dispositivos\n",
    "num_parts = 5\n",
    "\n",
    "# Fijar semillas\n",
    "fijar_semillas()\n",
    "\n",
    "# Ejecutar la simulación de Federated Learning\n",
    "accuracies = federated_learning(X, y, num_parts, num_iterations)\n",
    "\n",
    "# Mostrar las precisiones obtenidas en cada iteración\n",
    "print('Precisión en cada iteración:', accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc56efbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
