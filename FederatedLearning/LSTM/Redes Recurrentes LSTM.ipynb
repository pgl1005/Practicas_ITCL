{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccee670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ec305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610acee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
      "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
      "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
      "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
      "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
      "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
      "\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
      "0                  6                        25                    1   \n",
      "1                  1                         1                    7   \n",
      "2                  1                         1                    7   \n",
      "3                  1                         1                    7   \n",
      "4                  1                         1                    7   \n",
      "\n",
      "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
      "0                 1  ...          No      No                   No   \n",
      "1                 3  ...          No      Up                   No   \n",
      "2                 2  ...          No      No                   No   \n",
      "3                 2  ...          No      Up                   No   \n",
      "4                 1  ...          No  Steady                   No   \n",
      "\n",
      "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
      "0                   No                        No                       No   \n",
      "1                   No                        No                       No   \n",
      "2                   No                        No                       No   \n",
      "3                   No                        No                       No   \n",
      "4                   No                        No                       No   \n",
      "\n",
      "   metformin-pioglitazone  change diabetesMed readmitted  \n",
      "0                      No      No          No         NO  \n",
      "1                      No      Ch         Yes        >30  \n",
      "2                      No      No         Yes         NO  \n",
      "3                      No      Ch         Yes         NO  \n",
      "4                      No      Ch         Yes         NO  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             101766 non-null  object\n",
      " 23  A1Cresult                 101766 non-null  object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "encounter_id                0\n",
      "patient_nbr                 0\n",
      "race                        0\n",
      "gender                      0\n",
      "age                         0\n",
      "weight                      0\n",
      "admission_type_id           0\n",
      "discharge_disposition_id    0\n",
      "admission_source_id         0\n",
      "time_in_hospital            0\n",
      "payer_code                  0\n",
      "medical_specialty           0\n",
      "num_lab_procedures          0\n",
      "num_procedures              0\n",
      "num_medications             0\n",
      "number_outpatient           0\n",
      "number_emergency            0\n",
      "number_inpatient            0\n",
      "diag_1                      0\n",
      "diag_2                      0\n",
      "diag_3                      0\n",
      "number_diagnoses            0\n",
      "max_glu_serum               0\n",
      "A1Cresult                   0\n",
      "metformin                   0\n",
      "repaglinide                 0\n",
      "nateglinide                 0\n",
      "chlorpropamide              0\n",
      "glimepiride                 0\n",
      "acetohexamide               0\n",
      "glipizide                   0\n",
      "glyburide                   0\n",
      "tolbutamide                 0\n",
      "pioglitazone                0\n",
      "rosiglitazone               0\n",
      "acarbose                    0\n",
      "miglitol                    0\n",
      "troglitazone                0\n",
      "tolazamide                  0\n",
      "examide                     0\n",
      "citoglipton                 0\n",
      "insulin                     0\n",
      "glyburide-metformin         0\n",
      "glipizide-metformin         0\n",
      "glimepiride-pioglitazone    0\n",
      "metformin-rosiglitazone     0\n",
      "metformin-pioglitazone      0\n",
      "change                      0\n",
      "diabetesMed                 0\n",
      "readmitted                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "print(df.head())\n",
    "\n",
    "# Resumen de la información del dataset\n",
    "print(df.info())\n",
    "\n",
    "# Mostrar la cantidad de valores nulos por columna\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd3f7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_18280\\4281049621.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('diabetic_data.csv', na_values='?')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encounter_id                    0\n",
      "patient_nbr                     0\n",
      "race                         2273\n",
      "gender                          0\n",
      "age                             0\n",
      "weight                      98569\n",
      "admission_type_id               0\n",
      "discharge_disposition_id        0\n",
      "admission_source_id             0\n",
      "time_in_hospital                0\n",
      "payer_code                  40256\n",
      "medical_specialty           49949\n",
      "num_lab_procedures              0\n",
      "num_procedures                  0\n",
      "num_medications                 0\n",
      "number_outpatient               0\n",
      "number_emergency                0\n",
      "number_inpatient                0\n",
      "diag_1                         21\n",
      "diag_2                        358\n",
      "diag_3                       1423\n",
      "number_diagnoses                0\n",
      "max_glu_serum                   0\n",
      "A1Cresult                       0\n",
      "metformin                       0\n",
      "repaglinide                     0\n",
      "nateglinide                     0\n",
      "chlorpropamide                  0\n",
      "glimepiride                     0\n",
      "acetohexamide                   0\n",
      "glipizide                       0\n",
      "glyburide                       0\n",
      "tolbutamide                     0\n",
      "pioglitazone                    0\n",
      "rosiglitazone                   0\n",
      "acarbose                        0\n",
      "miglitol                        0\n",
      "troglitazone                    0\n",
      "tolazamide                      0\n",
      "examide                         0\n",
      "citoglipton                     0\n",
      "insulin                         0\n",
      "glyburide-metformin             0\n",
      "glipizide-metformin             0\n",
      "glimepiride-pioglitazone        0\n",
      "metformin-rosiglitazone         0\n",
      "metformin-pioglitazone          0\n",
      "change                          0\n",
      "diabetesMed                     0\n",
      "readmitted                      0\n",
      "dtype: int64\n",
      "El archivo modificado ha sido guardado como 'diabetic_data_modified.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV, tratando '?' como valores nulos\n",
    "df = pd.read_csv('diabetic_data.csv', na_values='?')\n",
    "\n",
    "# Mostrar la cantidad de valores nulos por columna\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "df.to_csv('diabetic_data_modified.csv', index=False)\n",
    "\n",
    "print(\"El archivo modificado ha sido guardado como 'diabetic_data_modified.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfde5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Procesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6802feef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_18280\\2766882862.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('diabetic_data_modified.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos procesados y guardados en 'processed_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('diabetic_data_modified.csv')\n",
    "\n",
    "# Asegurarse de manejar correctamente los valores nulos\n",
    "# Identificar las columnas con valores nulos según la descripción proporcionada\n",
    "cols_with_missing = ['race', 'weight', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "# Imputar los valores nulos con la moda para variables categóricas\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cols_with_missing] = categorical_imputer.fit_transform(df[cols_with_missing])\n",
    "\n",
    "# Limpiar y convertir 'weight' a valores numéricos y luego categorizarlo\n",
    "def clean_weight(weight_str):\n",
    "    if weight_str == \"?\":\n",
    "        return None\n",
    "    elif weight_str.startswith(\">\"):\n",
    "        return float(weight_str[1:]) + 1  # Incrementar en 1 para asegurar que los límites sean correctos\n",
    "    elif weight_str.startswith(\"[\"):\n",
    "        return float(weight_str.strip(\"[]\").split(\"-\")[0])\n",
    "    elif weight_str == \"Unknown\":\n",
    "        return None\n",
    "    else:\n",
    "        return float(weight_str)\n",
    "\n",
    "df['weight'] = df['weight'].apply(clean_weight)\n",
    "\n",
    "# Definir los rangos de peso y codificar 'weight'\n",
    "weight_ranges = ['[0-25)', '[25-50)', '[50-75)', '[75-100)', '[100-125)', '[125-150)', '[150-175)', '[175-200)', '>200']\n",
    "df['weight_category'] = pd.cut(df['weight'], bins=[0, 25, 50, 75, 100, 125, 150, 175, 200, float('inf')], labels=weight_ranges, right=False)\n",
    "\n",
    "# Eliminar la columna original 'weight'\n",
    "df.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "# Función para asignar categorías a los códigos ICD-9\n",
    "def assign_icd_category(icd_code):\n",
    "    if pd.isnull(icd_code):\n",
    "        return 'Unknown'\n",
    "    if icd_code.startswith(('E', 'V')):\n",
    "        return 'E-V codes'\n",
    "    else:\n",
    "        code_number = int(icd_code.split('.')[0])  # Tomar solo el número de código ICD-9\n",
    "        if 1 <= code_number <= 139:\n",
    "            return '001-139'\n",
    "        elif 140 <= code_number <= 239:\n",
    "            return '140-239'\n",
    "        elif 240 <= code_number <= 279:\n",
    "            return '240-279'\n",
    "        elif 280 <= code_number <= 289:\n",
    "            return '280-289'\n",
    "        elif 290 <= code_number <= 319:\n",
    "            return '290-319'\n",
    "        elif 320 <= code_number <= 389:\n",
    "            return '320-389'\n",
    "        elif 390 <= code_number <= 459:\n",
    "            return '390-459'\n",
    "        elif 460 <= code_number <= 519:\n",
    "            return '460-519'\n",
    "        elif 520 <= code_number <= 579:\n",
    "            return '520-579'\n",
    "        elif 580 <= code_number <= 629:\n",
    "            return '580-629'\n",
    "        elif 630 <= code_number <= 679:\n",
    "            return '630-679'\n",
    "        elif 680 <= code_number <= 709:\n",
    "            return '680-709'\n",
    "        elif 710 <= code_number <= 739:\n",
    "            return '710-739'\n",
    "        elif 740 <= code_number <= 759:\n",
    "            return '740-759'\n",
    "        elif 760 <= code_number <= 779:\n",
    "            return '760-779'\n",
    "        elif 780 <= code_number <= 799:\n",
    "            return '780-799'\n",
    "        elif 800 <= code_number <= 999:\n",
    "            return '800-999'\n",
    "        else:\n",
    "            return 'Other'  # En caso de no encontrar una categoría válida\n",
    "\n",
    "# Aplicar la función a cada columna de diagnóstico\n",
    "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    df[col + '_category'] = df[col].apply(assign_icd_category)\n",
    "\n",
    "# Eliminar las columnas originales de diagnóstico\n",
    "df.drop(columns=['diag_1', 'diag_2', 'diag_3'], inplace=True)\n",
    "\n",
    "# Función para asignar valores únicos a las franjas de edad\n",
    "def age_to_value(age_str):\n",
    "    age_mapping = {\n",
    "        '[0-10)': 5,\n",
    "        '[10-20)': 15,\n",
    "        '[20-30)': 25,\n",
    "        '[30-40)': 35,\n",
    "        '[40-50)': 45,\n",
    "        '[50-60)': 55,\n",
    "        '[60-70)': 65,\n",
    "        '[70-80)': 75,\n",
    "        '[80-90)': 85,\n",
    "        '[90-100)': 95\n",
    "    }\n",
    "    return age_mapping.get(age_str, None)\n",
    "\n",
    "# Aplicar la función de agrupamiento de edades\n",
    "df['age'] = df['age'].apply(age_to_value)\n",
    "\n",
    "# Aplicar codificación one-hot a las variables categóricas, excluyendo 'age' ya que está mapeada a valores únicos\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'age' in categorical_cols:\n",
    "    categorical_cols.remove('age')\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(df[categorical_cols]))\n",
    "\n",
    "# Sustituir las columnas originales con las nuevas codificadas\n",
    "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "df.drop(columns=categorical_cols, inplace=True)\n",
    "df = pd.concat([df, encoded_cols], axis=1)\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "# df.to_csv('processed_data.csv', index=False)\n",
    "\n",
    "print(\"Datos procesados y guardados en 'processed_data.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6bcda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creación del modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391978e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1/1\n",
      "Entrenando modelo local 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 587ms/step - accuracy: 0.7155 - loss: 1.4090 - val_accuracy: 0.7340 - val_loss: 0.5884\n",
      "Epoch 2/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 586ms/step - accuracy: 0.7421 - loss: 0.5818 - val_accuracy: 0.7340 - val_loss: 0.5795\n",
      "Epoch 3/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 540ms/step - accuracy: 0.7344 - loss: 0.5827 - val_accuracy: 0.7340 - val_loss: 0.5799\n",
      "Epoch 4/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 473ms/step - accuracy: 0.7332 - loss: 0.5842 - val_accuracy: 0.7340 - val_loss: 0.5793\n",
      "Epoch 5/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 497ms/step - accuracy: 0.7279 - loss: 0.5900 - val_accuracy: 0.7340 - val_loss: 0.5792\n",
      "Epoch 6/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 479ms/step - accuracy: 0.7362 - loss: 0.5798 - val_accuracy: 0.7340 - val_loss: 0.5821\n",
      "Epoch 7/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 500ms/step - accuracy: 0.7302 - loss: 0.5859 - val_accuracy: 0.7340 - val_loss: 0.5793\n",
      "Epoch 8/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 521ms/step - accuracy: 0.7321 - loss: 0.5827 - val_accuracy: 0.7340 - val_loss: 0.5802\n",
      "Epoch 9/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 478ms/step - accuracy: 0.7366 - loss: 0.5801 - val_accuracy: 0.7340 - val_loss: 0.5809\n",
      "Epoch 10/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 509ms/step - accuracy: 0.7333 - loss: 0.5821 - val_accuracy: 0.7340 - val_loss: 0.5792\n",
      "Accuracy del modelo local 1 en datos de prueba: 0.73238\n",
      "Entrenando modelo local 2/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 510ms/step - accuracy: 0.7436 - loss: 1.3856 - val_accuracy: 0.7602 - val_loss: 0.5704\n",
      "Epoch 2/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 505ms/step - accuracy: 0.7649 - loss: 0.5573 - val_accuracy: 0.7602 - val_loss: 0.5519\n",
      "Epoch 3/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 528ms/step - accuracy: 0.7563 - loss: 0.5600 - val_accuracy: 0.7602 - val_loss: 0.5516\n",
      "Epoch 4/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 538ms/step - accuracy: 0.7554 - loss: 0.5601 - val_accuracy: 0.7602 - val_loss: 0.5513\n",
      "Epoch 5/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 571ms/step - accuracy: 0.7567 - loss: 0.5594 - val_accuracy: 0.7602 - val_loss: 0.5510\n",
      "Epoch 6/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 553ms/step - accuracy: 0.7558 - loss: 0.5593 - val_accuracy: 0.7602 - val_loss: 0.5516\n",
      "Epoch 7/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 527ms/step - accuracy: 0.7602 - loss: 0.5535 - val_accuracy: 0.7602 - val_loss: 0.5510\n",
      "Epoch 8/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 519ms/step - accuracy: 0.7597 - loss: 0.5549 - val_accuracy: 0.7602 - val_loss: 0.5535\n",
      "Epoch 9/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 565ms/step - accuracy: 0.7592 - loss: 0.5546 - val_accuracy: 0.7602 - val_loss: 0.5509\n",
      "Epoch 10/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 541ms/step - accuracy: 0.7599 - loss: 0.5543 - val_accuracy: 0.7602 - val_loss: 0.5508\n",
      "Accuracy del modelo local 2 en datos de prueba: 0.75804\n",
      "Entrenando modelo local 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 559ms/step - accuracy: 0.7492 - loss: 1.3933 - val_accuracy: 0.7594 - val_loss: 0.5607\n",
      "Epoch 2/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 543ms/step - accuracy: 0.7618 - loss: 0.5577 - val_accuracy: 0.7594 - val_loss: 0.5531\n",
      "Epoch 3/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 547ms/step - accuracy: 0.7555 - loss: 0.5618 - val_accuracy: 0.7594 - val_loss: 0.5518\n",
      "Epoch 4/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 539ms/step - accuracy: 0.7581 - loss: 0.5580 - val_accuracy: 0.7594 - val_loss: 0.5526\n",
      "Epoch 5/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 526ms/step - accuracy: 0.7561 - loss: 0.5601 - val_accuracy: 0.7594 - val_loss: 0.5521\n",
      "Epoch 6/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 578ms/step - accuracy: 0.7651 - loss: 0.5504 - val_accuracy: 0.7594 - val_loss: 0.5518\n",
      "Epoch 7/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 522ms/step - accuracy: 0.7601 - loss: 0.5536 - val_accuracy: 0.7594 - val_loss: 0.5521\n",
      "Epoch 8/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 513ms/step - accuracy: 0.7576 - loss: 0.5554 - val_accuracy: 0.7594 - val_loss: 0.5518\n",
      "Epoch 9/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 449ms/step - accuracy: 0.7581 - loss: 0.5558 - val_accuracy: 0.7594 - val_loss: 0.5518\n",
      "Epoch 10/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 509ms/step - accuracy: 0.7594 - loss: 0.5537 - val_accuracy: 0.7594 - val_loss: 0.5535\n",
      "Accuracy del modelo local 3 en datos de prueba: 0.75964\n",
      "Entrenando modelo local 4/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 566ms/step - accuracy: 0.7928 - loss: 1.3469 - val_accuracy: 0.8044 - val_loss: 0.5038\n",
      "Epoch 2/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 524ms/step - accuracy: 0.8063 - loss: 0.4998 - val_accuracy: 0.8044 - val_loss: 0.4947\n",
      "Epoch 3/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 511ms/step - accuracy: 0.8097 - loss: 0.4925 - val_accuracy: 0.8044 - val_loss: 0.4945\n",
      "Epoch 4/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 476ms/step - accuracy: 0.8079 - loss: 0.4928 - val_accuracy: 0.8044 - val_loss: 0.4950\n",
      "Epoch 5/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 475ms/step - accuracy: 0.8075 - loss: 0.4920 - val_accuracy: 0.8044 - val_loss: 0.4946\n",
      "Epoch 6/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 477ms/step - accuracy: 0.8049 - loss: 0.5004 - val_accuracy: 0.8044 - val_loss: 0.4955\n",
      "Epoch 7/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 464ms/step - accuracy: 0.8074 - loss: 0.4939 - val_accuracy: 0.8044 - val_loss: 0.4950\n",
      "Epoch 8/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 503ms/step - accuracy: 0.8067 - loss: 0.4936 - val_accuracy: 0.8044 - val_loss: 0.4943\n",
      "Epoch 9/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 493ms/step - accuracy: 0.8003 - loss: 0.5040 - val_accuracy: 0.8044 - val_loss: 0.4942\n",
      "Epoch 10/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 489ms/step - accuracy: 0.8066 - loss: 0.4931 - val_accuracy: 0.8044 - val_loss: 0.4954\n",
      "Accuracy del modelo local 4 en datos de prueba: 0.80533\n",
      "Entrenando modelo local 5/5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 506ms/step - accuracy: 0.7876 - loss: 1.3666 - val_accuracy: 0.7938 - val_loss: 0.5251\n",
      "Epoch 2/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 510ms/step - accuracy: 0.7990 - loss: 0.5159 - val_accuracy: 0.7938 - val_loss: 0.5098\n",
      "Epoch 3/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 501ms/step - accuracy: 0.7938 - loss: 0.5143 - val_accuracy: 0.7938 - val_loss: 0.5108\n",
      "Epoch 4/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 479ms/step - accuracy: 0.7971 - loss: 0.5093 - val_accuracy: 0.7938 - val_loss: 0.5094\n",
      "Epoch 5/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 526ms/step - accuracy: 0.7947 - loss: 0.5139 - val_accuracy: 0.7938 - val_loss: 0.5100\n",
      "Epoch 6/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 494ms/step - accuracy: 0.7996 - loss: 0.5047 - val_accuracy: 0.7938 - val_loss: 0.5094\n",
      "Epoch 7/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 491ms/step - accuracy: 0.7924 - loss: 0.5146 - val_accuracy: 0.7938 - val_loss: 0.5099\n",
      "Epoch 8/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 481ms/step - accuracy: 0.7943 - loss: 0.5116 - val_accuracy: 0.7938 - val_loss: 0.5089\n",
      "Epoch 9/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 555ms/step - accuracy: 0.7943 - loss: 0.5112 - val_accuracy: 0.7938 - val_loss: 0.5092\n",
      "Epoch 10/10\n",
      "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 533ms/step - accuracy: 0.7950 - loss: 0.5110 - val_accuracy: 0.7938 - val_loss: 0.5104\n",
      "Accuracy del modelo local 5 en datos de prueba: 0.79477\n",
      "Creando modelo global\n",
      "Accuracies de los modelos locales:\n",
      "Modelo local 1: 0.73238\n",
      "Modelo local 2: 0.75804\n",
      "Modelo local 3: 0.75964\n",
      "Modelo local 4: 0.80533\n",
      "Modelo local 5: 0.79477\n",
      "Accuracy del modelo global después de la iteración: 0.77003\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Función para cargar los datos\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# Función para crear el modelo LSTM\n",
    "def crear_modelo_lstm(input_shape, learning_rate=0.001, dropout_rate=0.5, regularization_rate=0.01):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(128, input_shape=input_shape, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(regularization_rate)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.LSTM(64, kernel_regularizer=tf.keras.regularizers.l2(regularization_rate)),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Función de entrenamiento en cada dispositivo\n",
    "def train_on_device(X_train, y_train, input_shape, epochs, learning_rate, batch_size):\n",
    "    model = crear_modelo_lstm(input_shape, learning_rate)\n",
    "    model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.1, verbose=1)\n",
    "    return model\n",
    "\n",
    "# Función para dividir los datos\n",
    "def split_data(X, y, num_parts):\n",
    "    X_splits = np.array_split(X, num_parts)\n",
    "    y_splits = np.array_split(y, num_parts)\n",
    "    return X_splits, y_splits\n",
    "\n",
    "# Función para preprocesar datos una sola vez\n",
    "def preprocess_data(X, y, num_parts):\n",
    "    X_splits, y_splits = split_data(X, y, num_parts)\n",
    "    scalers = [StandardScaler().fit(X_split) for X_split in X_splits]\n",
    "    X_scaled_splits = [scaler.transform(X_split) for scaler, X_split in zip(scalers, X_splits)]\n",
    "    X_scaled_reshaped = [X_scaled.reshape(-1, X.shape[1], 1) for X_scaled in X_scaled_splits]\n",
    "    return X_scaled_reshaped, y_splits, scalers\n",
    "\n",
    "# Función principal para la simulación de Federated Learning\n",
    "def federated_learning(X, y, num_parts, num_iterations, epochs=6, learning_rate=0.001, batch_size=64):\n",
    "    all_accuracies = []\n",
    "    local_accuracies = []\n",
    "\n",
    "    X_scaled_splits, y_splits, scalers = preprocess_data(X, y, num_parts)\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f'Iteración {iteration + 1}/{num_iterations}')\n",
    "        local_models = []\n",
    "\n",
    "        for i in range(num_parts):\n",
    "            print(f'Entrenando modelo local {i + 1}/{num_parts}')\n",
    "            X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled_splits[i], y_splits[i], test_size=0.4, random_state=iteration, stratify=y_splits[i])\n",
    "            \n",
    "            local_model = train_on_device(X_train_scaled, y_train, input_shape=(X.shape[1], 1), epochs=epochs, learning_rate=learning_rate, batch_size=batch_size)\n",
    "            local_models.append(local_model)\n",
    "            \n",
    "            # Evaluar el modelo local en datos de prueba local\n",
    "            loss_local, accuracy_local = local_model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "            local_accuracies.append(accuracy_local)\n",
    "            print(f'Accuracy del modelo local {i + 1} en datos de prueba: {accuracy_local:.5f}')\n",
    "\n",
    "        # Crear el modelo global combinando los modelos locales\n",
    "        print('Creando modelo global')\n",
    "        global_model = crear_modelo_lstm(input_shape=(X.shape[1], 1))\n",
    "        \n",
    "        # Promediar los pesos capa por capa (Federated Averaging)\n",
    "        global_weights = [np.mean([model.get_weights()[layer] for model in local_models], axis=0) for layer in range(len(local_models[0].get_weights()))]\n",
    "        global_model.set_weights(global_weights)\n",
    "        \n",
    "        # Evaluar el modelo global en datos de prueba combinados\n",
    "        X_test_combined = np.vstack([X_scaled_splits[i] for i in range(num_parts)])\n",
    "        y_test_combined = np.hstack([y_splits[i] for i in range(num_parts)])\n",
    "        \n",
    "        loss_global, accuracy_global = global_model.evaluate(X_test_combined, y_test_combined, verbose=0)\n",
    "        \n",
    "        all_accuracies.append(accuracy_global)\n",
    "    \n",
    "    return all_accuracies, local_accuracies\n",
    "\n",
    "# Cargar datos desde el archivo CSV\n",
    "df = load_data('processed_data.csv')\n",
    "\n",
    "# Seleccionar características y etiquetas\n",
    "X = df.drop(columns=['diabetesMed_Yes'])\n",
    "y = df['diabetesMed_Yes']\n",
    "\n",
    "# Ejecutar la simulación de Federated Learning\n",
    "accuracies_global, accuracies_local = federated_learning(X, y, num_parts=5, num_iterations=1, epochs=10, learning_rate=0.001, batch_size=64)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f'Accuracies de los modelos locales:')\n",
    "for i, acc in enumerate(accuracies_local):\n",
    "    print(f'Modelo local {i + 1}: {acc:.5f}')\n",
    "    \n",
    "print(f'Accuracy del modelo global después de la iteración: {accuracies_global[0]:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844c34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
