{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eccee670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model, clone_model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.random import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c9bdc8",
   "metadata": {},
   "source": [
    "### Importación de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "610acee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
      "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
      "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
      "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
      "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
      "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
      "\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
      "0                  6                        25                    1   \n",
      "1                  1                         1                    7   \n",
      "2                  1                         1                    7   \n",
      "3                  1                         1                    7   \n",
      "4                  1                         1                    7   \n",
      "\n",
      "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
      "0                 1  ...          No      No                   No   \n",
      "1                 3  ...          No      Up                   No   \n",
      "2                 2  ...          No      No                   No   \n",
      "3                 2  ...          No      Up                   No   \n",
      "4                 1  ...          No  Steady                   No   \n",
      "\n",
      "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
      "0                   No                        No                       No   \n",
      "1                   No                        No                       No   \n",
      "2                   No                        No                       No   \n",
      "3                   No                        No                       No   \n",
      "4                   No                        No                       No   \n",
      "\n",
      "   metformin-pioglitazone  change diabetesMed readmitted  \n",
      "0                      No      No          No         NO  \n",
      "1                      No      Ch         Yes        >30  \n",
      "2                      No      No         Yes         NO  \n",
      "3                      No      Ch         Yes         NO  \n",
      "4                      No      Ch         Yes         NO  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             101766 non-null  object\n",
      " 23  A1Cresult                 101766 non-null  object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n",
      "encounter_id                0\n",
      "patient_nbr                 0\n",
      "race                        0\n",
      "gender                      0\n",
      "age                         0\n",
      "weight                      0\n",
      "admission_type_id           0\n",
      "discharge_disposition_id    0\n",
      "admission_source_id         0\n",
      "time_in_hospital            0\n",
      "payer_code                  0\n",
      "medical_specialty           0\n",
      "num_lab_procedures          0\n",
      "num_procedures              0\n",
      "num_medications             0\n",
      "number_outpatient           0\n",
      "number_emergency            0\n",
      "number_inpatient            0\n",
      "diag_1                      0\n",
      "diag_2                      0\n",
      "diag_3                      0\n",
      "number_diagnoses            0\n",
      "max_glu_serum               0\n",
      "A1Cresult                   0\n",
      "metformin                   0\n",
      "repaglinide                 0\n",
      "nateglinide                 0\n",
      "chlorpropamide              0\n",
      "glimepiride                 0\n",
      "acetohexamide               0\n",
      "glipizide                   0\n",
      "glyburide                   0\n",
      "tolbutamide                 0\n",
      "pioglitazone                0\n",
      "rosiglitazone               0\n",
      "acarbose                    0\n",
      "miglitol                    0\n",
      "troglitazone                0\n",
      "tolazamide                  0\n",
      "examide                     0\n",
      "citoglipton                 0\n",
      "insulin                     0\n",
      "glyburide-metformin         0\n",
      "glipizide-metformin         0\n",
      "glimepiride-pioglitazone    0\n",
      "metformin-rosiglitazone     0\n",
      "metformin-pioglitazone      0\n",
      "change                      0\n",
      "diabetesMed                 0\n",
      "readmitted                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV\n",
    "df = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "# Mostrar las primeras filas del dataset\n",
    "print(df.head())\n",
    "\n",
    "# Resumen de la información del dataset\n",
    "print(df.info())\n",
    "\n",
    "# Mostrar la cantidad de valores nulos por columna\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfd3f7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_11596\\4281049621.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('diabetic_data.csv', na_values='?')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encounter_id                    0\n",
      "patient_nbr                     0\n",
      "race                         2273\n",
      "gender                          0\n",
      "age                             0\n",
      "weight                      98569\n",
      "admission_type_id               0\n",
      "discharge_disposition_id        0\n",
      "admission_source_id             0\n",
      "time_in_hospital                0\n",
      "payer_code                  40256\n",
      "medical_specialty           49949\n",
      "num_lab_procedures              0\n",
      "num_procedures                  0\n",
      "num_medications                 0\n",
      "number_outpatient               0\n",
      "number_emergency                0\n",
      "number_inpatient                0\n",
      "diag_1                         21\n",
      "diag_2                        358\n",
      "diag_3                       1423\n",
      "number_diagnoses                0\n",
      "max_glu_serum                   0\n",
      "A1Cresult                       0\n",
      "metformin                       0\n",
      "repaglinide                     0\n",
      "nateglinide                     0\n",
      "chlorpropamide                  0\n",
      "glimepiride                     0\n",
      "acetohexamide                   0\n",
      "glipizide                       0\n",
      "glyburide                       0\n",
      "tolbutamide                     0\n",
      "pioglitazone                    0\n",
      "rosiglitazone                   0\n",
      "acarbose                        0\n",
      "miglitol                        0\n",
      "troglitazone                    0\n",
      "tolazamide                      0\n",
      "examide                         0\n",
      "citoglipton                     0\n",
      "insulin                         0\n",
      "glyburide-metformin             0\n",
      "glipizide-metformin             0\n",
      "glimepiride-pioglitazone        0\n",
      "metformin-rosiglitazone         0\n",
      "metformin-pioglitazone          0\n",
      "change                          0\n",
      "diabetesMed                     0\n",
      "readmitted                      0\n",
      "dtype: int64\n",
      "El archivo modificado ha sido guardado como 'diabetic_data_modified.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Leer el archivo CSV, tratando '?' como valores nulos\n",
    "df = pd.read_csv('diabetic_data.csv', na_values='?')\n",
    "\n",
    "# Mostrar la cantidad de valores nulos por columna\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Guardar el DataFrame modificado en un nuevo archivo CSV\n",
    "df.to_csv('diabetic_data_modified.csv', index=False)\n",
    "\n",
    "print(\"El archivo modificado ha sido guardado como 'diabetic_data_modified.csv'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897754d8",
   "metadata": {},
   "source": [
    "### Procesamiento de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6802feef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\AppData\\Local\\Temp\\ipykernel_11596\\2766882862.py:2: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('diabetic_data_modified.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos procesados y guardados en 'processed_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "df = pd.read_csv('diabetic_data_modified.csv')\n",
    "\n",
    "# Asegurarse de manejar correctamente los valores nulos\n",
    "# Identificar las columnas con valores nulos según la descripción proporcionada\n",
    "cols_with_missing = ['race', 'weight', 'payer_code', 'medical_specialty', 'diag_1', 'diag_2', 'diag_3']\n",
    "\n",
    "# Imputar los valores nulos con la moda para variables categóricas\n",
    "categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cols_with_missing] = categorical_imputer.fit_transform(df[cols_with_missing])\n",
    "\n",
    "# Limpiar y convertir 'weight' a valores numéricos y luego categorizarlo\n",
    "def clean_weight(weight_str):\n",
    "    if weight_str == \"?\":\n",
    "        return None\n",
    "    elif weight_str.startswith(\">\"):\n",
    "        return float(weight_str[1:]) + 1  # Incrementar en 1 para asegurar que los límites sean correctos\n",
    "    elif weight_str.startswith(\"[\"):\n",
    "        return float(weight_str.strip(\"[]\").split(\"-\")[0])\n",
    "    elif weight_str == \"Unknown\":\n",
    "        return None\n",
    "    else:\n",
    "        return float(weight_str)\n",
    "\n",
    "df['weight'] = df['weight'].apply(clean_weight)\n",
    "\n",
    "# Definir los rangos de peso y codificar 'weight'\n",
    "weight_ranges = ['[0-25)', '[25-50)', '[50-75)', '[75-100)', '[100-125)', '[125-150)', '[150-175)', '[175-200)', '>200']\n",
    "df['weight_category'] = pd.cut(df['weight'], bins=[0, 25, 50, 75, 100, 125, 150, 175, 200, float('inf')], labels=weight_ranges, right=False)\n",
    "\n",
    "# Eliminar la columna original 'weight'\n",
    "df.drop(columns=['weight'], inplace=True)\n",
    "\n",
    "# Función para asignar categorías a los códigos ICD-9\n",
    "def assign_icd_category(icd_code):\n",
    "    if pd.isnull(icd_code):\n",
    "        return 'Unknown'\n",
    "    if icd_code.startswith(('E', 'V')):\n",
    "        return 'E-V codes'\n",
    "    else:\n",
    "        code_number = int(icd_code.split('.')[0])  # Tomar solo el número de código ICD-9\n",
    "        if 1 <= code_number <= 139:\n",
    "            return '001-139'\n",
    "        elif 140 <= code_number <= 239:\n",
    "            return '140-239'\n",
    "        elif 240 <= code_number <= 279:\n",
    "            return '240-279'\n",
    "        elif 280 <= code_number <= 289:\n",
    "            return '280-289'\n",
    "        elif 290 <= code_number <= 319:\n",
    "            return '290-319'\n",
    "        elif 320 <= code_number <= 389:\n",
    "            return '320-389'\n",
    "        elif 390 <= code_number <= 459:\n",
    "            return '390-459'\n",
    "        elif 460 <= code_number <= 519:\n",
    "            return '460-519'\n",
    "        elif 520 <= code_number <= 579:\n",
    "            return '520-579'\n",
    "        elif 580 <= code_number <= 629:\n",
    "            return '580-629'\n",
    "        elif 630 <= code_number <= 679:\n",
    "            return '630-679'\n",
    "        elif 680 <= code_number <= 709:\n",
    "            return '680-709'\n",
    "        elif 710 <= code_number <= 739:\n",
    "            return '710-739'\n",
    "        elif 740 <= code_number <= 759:\n",
    "            return '740-759'\n",
    "        elif 760 <= code_number <= 779:\n",
    "            return '760-779'\n",
    "        elif 780 <= code_number <= 799:\n",
    "            return '780-799'\n",
    "        elif 800 <= code_number <= 999:\n",
    "            return '800-999'\n",
    "        else:\n",
    "            return 'Other'  # En caso de no encontrar una categoría válida\n",
    "\n",
    "# Aplicar la función a cada columna de diagnóstico\n",
    "for col in ['diag_1', 'diag_2', 'diag_3']:\n",
    "    df[col + '_category'] = df[col].apply(assign_icd_category)\n",
    "\n",
    "# Eliminar las columnas originales de diagnóstico\n",
    "df.drop(columns=['diag_1', 'diag_2', 'diag_3'], inplace=True)\n",
    "\n",
    "# Función para asignar valores únicos a las franjas de edad\n",
    "def age_to_value(age_str):\n",
    "    age_mapping = {\n",
    "        '[0-10)': 5,\n",
    "        '[10-20)': 15,\n",
    "        '[20-30)': 25,\n",
    "        '[30-40)': 35,\n",
    "        '[40-50)': 45,\n",
    "        '[50-60)': 55,\n",
    "        '[60-70)': 65,\n",
    "        '[70-80)': 75,\n",
    "        '[80-90)': 85,\n",
    "        '[90-100)': 95\n",
    "    }\n",
    "    return age_mapping.get(age_str, None)\n",
    "\n",
    "# Aplicar la función de agrupamiento de edades\n",
    "df['age'] = df['age'].apply(age_to_value)\n",
    "\n",
    "# Aplicar codificación one-hot a las variables categóricas, excluyendo 'age' ya que está mapeada a valores únicos\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "if 'age' in categorical_cols:\n",
    "    categorical_cols.remove('age')\n",
    "encoder = OneHotEncoder(drop='first', sparse_output=False)\n",
    "encoded_cols = pd.DataFrame(encoder.fit_transform(df[categorical_cols]))\n",
    "\n",
    "# Sustituir las columnas originales con las nuevas codificadas\n",
    "encoded_cols.columns = encoder.get_feature_names_out(categorical_cols)\n",
    "df.drop(columns=categorical_cols, inplace=True)\n",
    "df = pd.concat([df, encoded_cols], axis=1)\n",
    "\n",
    "# Guardar el resultado en un nuevo archivo CSV\n",
    "# df.to_csv('processed_data.csv', index=False)\n",
    "\n",
    "print(\"Datos procesados y guardados en 'processed_data.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8986f",
   "metadata": {},
   "source": [
    "### Creación del modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc576c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración 1/1\n",
      "Entrenando modelo local 1/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 181ms/step - accuracy: 0.7344 - loss: 0.5954 - val_accuracy: 0.7266 - val_loss: 0.5869\n",
      "Epoch 2/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 173ms/step - accuracy: 0.7286 - loss: 0.5873 - val_accuracy: 0.7266 - val_loss: 0.5897\n",
      "Epoch 3/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 192ms/step - accuracy: 0.7380 - loss: 0.5759 - val_accuracy: 0.7266 - val_loss: 0.5867\n",
      "Epoch 4/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 206ms/step - accuracy: 0.7358 - loss: 0.5783 - val_accuracy: 0.7266 - val_loss: 0.5866\n",
      "Epoch 5/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 204ms/step - accuracy: 0.7347 - loss: 0.5798 - val_accuracy: 0.7266 - val_loss: 0.5873\n",
      "Entrenando modelo local 2/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 219ms/step - accuracy: 0.7515 - loss: 0.5758 - val_accuracy: 0.7503 - val_loss: 0.5596\n",
      "Epoch 2/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 180ms/step - accuracy: 0.7646 - loss: 0.5466 - val_accuracy: 0.7503 - val_loss: 0.5684\n",
      "Epoch 3/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 173ms/step - accuracy: 0.7568 - loss: 0.5580 - val_accuracy: 0.7503 - val_loss: 0.5625\n",
      "Epoch 4/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 154ms/step - accuracy: 0.7559 - loss: 0.5563 - val_accuracy: 0.7503 - val_loss: 0.5624\n",
      "Epoch 5/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 181ms/step - accuracy: 0.7657 - loss: 0.5453 - val_accuracy: 0.7503 - val_loss: 0.5622\n",
      "Entrenando modelo local 3/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 152ms/step - accuracy: 0.7560 - loss: 0.5695 - val_accuracy: 0.7544 - val_loss: 0.5740\n",
      "Epoch 2/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 165ms/step - accuracy: 0.7637 - loss: 0.5478 - val_accuracy: 0.7544 - val_loss: 0.5589\n",
      "Epoch 3/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 188ms/step - accuracy: 0.7599 - loss: 0.5507 - val_accuracy: 0.7544 - val_loss: 0.5589\n",
      "Epoch 4/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 200ms/step - accuracy: 0.7582 - loss: 0.5544 - val_accuracy: 0.7544 - val_loss: 0.5577\n",
      "Epoch 5/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 201ms/step - accuracy: 0.7639 - loss: 0.5468 - val_accuracy: 0.7544 - val_loss: 0.5589\n",
      "Entrenando modelo local 4/5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 211ms/step - accuracy: 0.8037 - loss: 0.5215 - val_accuracy: 0.8019 - val_loss: 0.4980\n",
      "Epoch 2/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 211ms/step - accuracy: 0.7991 - loss: 0.5021 - val_accuracy: 0.8019 - val_loss: 0.4979\n",
      "Epoch 3/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 232ms/step - accuracy: 0.8082 - loss: 0.4891 - val_accuracy: 0.8019 - val_loss: 0.4975\n",
      "Epoch 4/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 221ms/step - accuracy: 0.8040 - loss: 0.4951 - val_accuracy: 0.8019 - val_loss: 0.4979\n",
      "Epoch 5/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 226ms/step - accuracy: 0.8055 - loss: 0.4930 - val_accuracy: 0.8019 - val_loss: 0.5004\n",
      "Entrenando modelo local 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 232ms/step - accuracy: 0.7984 - loss: 0.5299 - val_accuracy: 0.7904 - val_loss: 0.5135\n",
      "Epoch 2/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 188ms/step - accuracy: 0.7912 - loss: 0.5122 - val_accuracy: 0.7904 - val_loss: 0.5056\n",
      "Epoch 3/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 155ms/step - accuracy: 0.7974 - loss: 0.5030 - val_accuracy: 0.7904 - val_loss: 0.5136\n",
      "Epoch 4/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 163ms/step - accuracy: 0.7977 - loss: 0.5041 - val_accuracy: 0.7904 - val_loss: 0.5132\n",
      "Epoch 5/5\n",
      "\u001b[1m306/306\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 149ms/step - accuracy: 0.8030 - loss: 0.4964 - val_accuracy: 0.7904 - val_loss: 0.5136\n",
      "Creando modelo global\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_splits' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 86\u001b[0m\n\u001b[0;32m     83\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiabetesMed_Yes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Ejecutar la simulación de Federated Learning\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m federated_learning(X, y, num_parts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, num_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 67\u001b[0m, in \u001b[0;36mfederated_learning\u001b[1;34m(X, y, num_parts, num_iterations, epochs, learning_rate)\u001b[0m\n\u001b[0;32m     64\u001b[0m global_model\u001b[38;5;241m.\u001b[39mset_weights(global_weights)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo global en datos de prueba combinados\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m X_test_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([scalers[i]\u001b[38;5;241m.\u001b[39mtransform(X_splits[i])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X_splits[i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_parts)])\n\u001b[0;32m     68\u001b[0m y_test_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([y_splits[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_parts)])\n\u001b[0;32m     70\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m global_model\u001b[38;5;241m.\u001b[39mevaluate(X_test_combined, y_test_combined, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 67\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     64\u001b[0m global_model\u001b[38;5;241m.\u001b[39mset_weights(global_weights)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Evaluar el modelo global en datos de prueba combinados\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m X_test_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([scalers[i]\u001b[38;5;241m.\u001b[39mtransform(X_splits[i])\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, X_splits[i]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_parts)])\n\u001b[0;32m     68\u001b[0m y_test_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([y_splits[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_parts)])\n\u001b[0;32m     70\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m global_model\u001b[38;5;241m.\u001b[39mevaluate(X_test_combined, y_test_combined, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_splits' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# Función para cargar los datos\n",
    "def load_data(filepath):\n",
    "    return pd.read_csv(filepath)\n",
    "\n",
    "# Función para crear el modelo LSTM\n",
    "def crear_modelo_lstm(input_shape, learning_rate=0.001):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True),\n",
    "        tf.keras.layers.LSTM(32),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Función de entrenamiento en cada dispositivo\n",
    "def train_on_device(X_train, y_train, input_shape, epochs, learning_rate):\n",
    "    model = crear_modelo_lstm(input_shape, learning_rate)\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, verbose=1)\n",
    "    return model\n",
    "\n",
    "# Función para dividir los datos\n",
    "def split_data(X, y, num_parts):\n",
    "    X_splits = np.array_split(X, num_parts)\n",
    "    y_splits = np.array_split(y, num_parts)\n",
    "    return X_splits, y_splits\n",
    "\n",
    "# Función para preprocesar datos una sola vez\n",
    "def preprocess_data(X, y, num_parts):\n",
    "    X_splits, y_splits = split_data(X, y, num_parts)\n",
    "    scalers = [StandardScaler().fit(X_split) for X_split in X_splits]\n",
    "    X_scaled_splits = [scaler.transform(X_split) for scaler, X_split in zip(scalers, X_splits)]\n",
    "    X_scaled_reshaped = [X_scaled.reshape(-1, X.shape[1], 1) for X_scaled in X_scaled_splits]\n",
    "    return X_scaled_reshaped, y_splits, scalers\n",
    "\n",
    "# Función principal para la simulación de Federated Learning\n",
    "def federated_learning(X, y, num_parts, num_iterations, epochs=5, learning_rate=0.001):\n",
    "    all_accuracies = []\n",
    "\n",
    "    X_scaled_splits, y_splits, scalers = preprocess_data(X, y, num_parts)\n",
    "\n",
    "    for iteration in range(num_iterations):\n",
    "        print(f'Iteración {iteration + 1}/{num_iterations}')\n",
    "        local_models = []\n",
    "\n",
    "        for i in range(num_parts):\n",
    "            print(f'Entrenando modelo local {i + 1}/{num_parts}')\n",
    "            X_train_scaled, X_test_scaled, y_train, y_test = train_test_split(X_scaled_splits[i], y_splits[i], test_size=0.4, random_state=iteration, stratify=y_splits[i])\n",
    "            \n",
    "            local_model = train_on_device(X_train_scaled, y_train, input_shape=(X.shape[1], 1), epochs=epochs, learning_rate=learning_rate)\n",
    "            local_models.append(local_model)\n",
    "        \n",
    "        # Crear el modelo global combinando los modelos locales\n",
    "        print('Creando modelo global')\n",
    "        global_model = crear_modelo_lstm(input_shape=(X.shape[1], 1))\n",
    "        \n",
    "        # Promediar los pesos capa por capa (Federated Averaging)\n",
    "        global_weights = [np.mean([model.get_weights()[layer] for model in local_models], axis=0) for layer in range(len(local_models[0].get_weights()))]\n",
    "        global_model.set_weights(global_weights)\n",
    "        \n",
    "        # Evaluar el modelo global en datos de prueba combinados\n",
    "        X_test_combined = np.vstack([X_scaled_splits[i] for i in range(num_parts)])\n",
    "        y_test_combined = np.hstack([y_splits[i] for i in range(num_parts)])\n",
    "        \n",
    "        loss, accuracy = global_model.evaluate(X_test_combined, y_test_combined, verbose=0)\n",
    "        \n",
    "        all_accuracies.append(accuracy)\n",
    "        print(f'Accuracy del modelo global después de {iteration + 1} iteración: {accuracy:.5f}\\n')\n",
    "    \n",
    "    return all_accuracies\n",
    "\n",
    "\n",
    "# Cargar datos desde el archivo CSV\n",
    "df = load_data('processed_data.csv')\n",
    "\n",
    "# Seleccionar características y etiquetas\n",
    "X = df.drop(columns=['diabetesMed_Yes'])\n",
    "y = df['diabetesMed_Yes']\n",
    "\n",
    "# Ejecutar la simulación de Federated Learning\n",
    "accuracies = federated_learning(X, y, num_parts=5, num_iterations=1, epochs=5, learning_rate=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844c34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
