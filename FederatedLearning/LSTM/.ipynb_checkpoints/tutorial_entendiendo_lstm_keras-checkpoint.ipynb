{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g0vIZOS__N5y"
   },
   "source": [
    "# ENTENDIENDO EL MÓDULO \"LSTM\" EN KERAS\n",
    "\n",
    "En este tutorial vamos a entender cómo usar las principales opciones del módulo \"LSTM\" de Keras para la creación de Redes LSTM.\n",
    "\n",
    "Contenido:\n",
    "1. [Redes LSTM: breve repaso](#scrollTo=RemDAOPx5auE&line=1&uniqifier=1)\n",
    "2. [Keras y la celda LSTM básica](#scrollTo=CnqQ4VlH_WoL&line=10&uniqifier=1)\n",
    "3. [La opción \"return_sequences\"](#scrollTo=3hMNGse7BFKn&line=19&uniqifier=1)\n",
    "4. [La opción \"return_state\"](#scrollTo=J6fhsNIiE4jF&line=14&uniqifier=1)\n",
    "5. [Usando \"return_sequences\" y \"return_states\" simultáneamente](#scrollTo=3DSMNdaOJKXr&line=1&uniqifier=1)\n",
    "6. [Celda LSTM + capa \"Dense\"](#scrollTo=-ktFF1d-4ldC&line=9&uniqifier=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RemDAOPx5auE"
   },
   "source": [
    "## 1. Redes LSTM: breve repaso\n",
    "\n",
    "La Red LSTM tiene dos elementos centrales:\n",
    "\n",
    "- El estado oculto, que es como la **memoria de corto plazo** y\n",
    "- La celda de estado, que es como la **memoria de largo plazo**\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1D-KyGNut7oVSMgQChiIRiJ1uLSih4omw)\n",
    "\n",
    "Así que durante el entrenamiento la Red LSTM aprende a determinar qué información de corto y largo plazo es relevante para interpretar correctamente la secuencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CnqQ4VlH_WoL"
   },
   "source": [
    "## 2. Keras y la celda LSTM básica\n",
    "\n",
    "En Keras una Red LSTM básica se conoce como una celda.\n",
    "\n",
    "En su versión por defecto la creamos definiendo dos parámetros:\n",
    "\n",
    "- `input_shape`: el tamaño de cada dato de entrada (*timesteps* x *features*)\n",
    "- `units`: el número de unidades de la celda. Este número de unidades definirá a su vez la complejidad (número de parámetros) de la celda así como el tamaño del dato de salida (*units*)\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1Ej1XGizCIGIkzvebVW1S1thNVeA5H03B)\n",
    "\n",
    "\n",
    "Veamos un ejemplo sencillo. Creemos una celda LSTM con estas características:\n",
    "\n",
    "- Entradas: secuencias de 3 elementos y 1 feature (`input_shape` de 3x1)\n",
    "- Unidades: 5 (`units`)\n",
    "\n",
    "Veamos cómo implementar esta celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3PVpIX8M3G-m",
    "outputId": "d6e331fc-b36d-44b9-f0d8-3c017ee11e0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 5)                 140       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140 (560.00 Byte)\n",
      "Trainable params: 140 (560.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 1)\n",
      "Tamaño de salida: (None, 5)\n",
      "----------------------------------------------------------------------\n",
      "Predicción (h_t):  [[ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]\n",
      "Tamaño predicción:  (1, 5)\n"
     ]
    }
   ],
   "source": [
    "# Importar modulos requeridos\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM\n",
    "from tensorflow.random import set_seed\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Función fijar semillas (para reproducibilidad de los resultados)\n",
    "def fijar_semillas():\n",
    "    set_seed(123)\n",
    "    np.random.seed(123)\n",
    "    random.seed(123)\n",
    "\n",
    "# Crear celda LSTM:\n",
    "# - input_shape de 3x1\n",
    "# - units = 5\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
    "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
    "modelo = Model(inputs=entrada, outputs=lstm_out)\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
    "pred = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (h_t): ', pred)\n",
    "print('Tamaño predicción: ', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLgNw0viAwRi"
   },
   "source": [
    "Vemos que la predicción (salida del modelo) tiene exactamente 5 elementos, el mismo número de unidades de la celda LSTM.\n",
    "\n",
    "Si ahora la entrada contiene 2 y no 1 *feature*, la salida seguirá teniendo 5 elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mp_kMP3x33_P",
    "outputId": "bd871894-d875-422a-d988-4a86c2b6d7b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 3, 2)]            0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 5)                 160       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 160 (640.00 Byte)\n",
      "Trainable params: 160 (640.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 2)\n",
      "Tamaño de salida: (None, 5)\n",
      "----------------------------------------------------------------------\n",
      "Predicción (h_t):  [[-0.09150496  0.05164478  0.19230194  0.07269354 -0.10549309]]\n",
      "Tamaño predicción:  (1, 5)\n"
     ]
    }
   ],
   "source": [
    "# Crear celda LSTM\n",
    "# - input_shape = 3 (timesteps) x 2 (features)\n",
    "# - units = 5\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,2))\n",
    "lstm_out = LSTM(5)(entrada)\n",
    "modelo = Model(inputs=entrada, outputs=lstm_out)\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([[0.5, 0.4, 0.3],\n",
    "                  [0.6, 0.9, 0.8]]).reshape((1,3,2))\n",
    "pred = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (h_t): ', pred)\n",
    "print('Tamaño predicción: ', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hMNGse7BFKn"
   },
   "source": [
    "## 3. La opción `return_sequences`\n",
    "\n",
    "En los ejemplos anteriores hemos usado las opciones por defecto.\n",
    "\n",
    "En particular, una de esas opciones por defecto es `return_sequences = False`.\n",
    "\n",
    "Con esta opción la salida de la celda únicamente contendrá la predicción correspondiente **último dato en la secuencia de entrada**:\n",
    "\n",
    "| *timestep* (entrada) | valor | salida ($h_t$)                   |\n",
    "|:--------------------:|:-----:|----------------------------------|\n",
    "| 1                    | 0.5   | -------------                              |\n",
    "| 2                    | 0.4   | -------------                              |\n",
    "| 3                    | 0.3   | [0.04, -0.06, 0.03, -0.05, 0.02] |\n",
    "\n",
    "\n",
    "Sin embargo, si hacemos `return_sequences=True` la celda retornará una predicción **por cada elemento en la secuencia de entrada**:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1H2sadt1RT46C2hJvdxvh6YloqCwMklsd)\n",
    "\n",
    "\n",
    "Es decir que ahora la salida será de tamaño *timesteps* (el tamaño de la secuencia de entrada) x *units* (el número de unidades de la celda LSTM).\n",
    "\n",
    "Veamos el mismo caso del primer ejemplo (entrada de 3x1) pero ahora con `return_sequences=True`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fUOAjbBK4j8y",
    "outputId": "63741a64-1140-4761-f682-929d437112b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 3, 5)              140       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140 (560.00 Byte)\n",
      "Trainable params: 140 (560.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 1)\n",
      "Tamaño de salida: (None, 3, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d5c5da472e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Predicción (h_t):  [[[ 0.02129798 -0.04037673  0.02123253 -0.02901676  0.01275784]\n",
      "  [ 0.03483645 -0.0609595   0.02958979 -0.04655094  0.02243249]\n",
      "  [ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]]\n",
      "Tamaño predicción:  (1, 3, 5)\n"
     ]
    }
   ],
   "source": [
    "# Crear celda LSTM\n",
    "# - input_shape = 3x1\n",
    "# - units = 5\n",
    "# - return_sequences = True\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,1))\n",
    "lstm_out = LSTM(5,\n",
    "                return_sequences=True)(entrada) # *** Celda LSTM con return_sequences=True\n",
    "modelo = Model(inputs=entrada, outputs=lstm_out)\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1))\n",
    "pred = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (h_t): ', pred)\n",
    "print('Tamaño predicción: ', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewA8c-fYER9i"
   },
   "source": [
    "Así que veamos la diferencia entre `return_sequences=False` y `return_sequences=True`:\n",
    "\n",
    "| *timestep* (entrada) | valor | salida ($h_t$) sin \"return_sequences\" | salida ($h_t$) con \"return_sequences\" |\n",
    "|:--------------------:|:-----:|---------------------------------------|---------------------------------------|\n",
    "| 1                    | 0.5   | -------------                                   | [0.02, -0.04, 0.02, -0.02, 0.01]      |\n",
    "| 2                    | 0.4   | -------------                                   | [0.03, -0.06, 0.02, -0.04, 0.02]      |\n",
    "| 3                    | 0.3   | [0.04, -0.06, 0.03, -0.05, 0.02]      | [0.04, -0.06, 0.03, -0.05, 0.02]      |\n",
    "\n",
    "Es decir que:\n",
    "\n",
    "> `return_sequences=True` retorna **todos** los estados ocultos\n",
    "\n",
    "Esta opción de `return_sequences=True` la podemos usar por ejemplo cuando queremos usar múltiples celdas LSTM (es decir conectar una después de la otra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6fhsNIiE4jF"
   },
   "source": [
    "## 4. La opción `return_state`\n",
    "\n",
    "Hasta este punto hemos visto que la Red LSTM únicamente retorna el estado oculto ($h_t$) pero no la celda de estado ($c_t$).\n",
    "\n",
    "Si queremos retornar el último estado oculto y el último valor de la celda de estado, debemos usar `return_states=True`:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1GpgZjw78ykBE2UT3FEUYiYaKTpOH0HAy)\n",
    "\n",
    "En este caso la celda retorna 2 salidas:\n",
    "\n",
    "- El último estado oculto $h_t$\n",
    "- El último valor en la celda de estado $c_t$\n",
    "\n",
    "Por ejemplo, creemos la misma celda LSTM del primer ejemplo (entrada 3x1, 5 unidades) pero ahora usemos `return_state=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g2O0n-lrHB7U",
    "outputId": "6516fce0-630d-4b2c-d0fa-5110c08f3e5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               [(None, 5),               140       \n",
      "                              (None, 5),                         \n",
      "                              (None, 5)]                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140 (560.00 Byte)\n",
      "Trainable params: 140 (560.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 1)\n",
      "Tamaño de salida: [(None, 5), (None, 5), (None, 5)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d5c5ec2a830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "Predicción (lstm_out):  [[ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]\n",
      "Tamaño predicción \"lstm_out\":  (1, 5)\n",
      "..................................................\n",
      "Predicción (h_t):  [[ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]\n",
      "Tamaño predicción \"h_t\":  (1, 5)\n",
      "..................................................\n",
      "Predicción (c_t):  [[ 0.08437636 -0.12790795  0.05566084 -0.11978056  0.05761085]]\n",
      "Tamaño predicción \"c_t\":  (1, 5)\n"
     ]
    }
   ],
   "source": [
    "# Crear celda LSTM\n",
    "# - input_shape = 3x1\n",
    "# - units = 5\n",
    "# - return_state = True\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
    "lstm_out, h_t, c_t = LSTM(5,\n",
    "                          return_state=True)(entrada) # ***Celda LSTM con return_state=True***\n",
    "modelo = Model(inputs=entrada, outputs=[lstm_out, h_t, c_t])\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1))\n",
    "pred, h, c = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (lstm_out): ', pred)\n",
    "print('Tamaño predicción \"lstm_out\": ', pred.shape)\n",
    "print('.'*50)\n",
    "print('Predicción (h_t): ', h)\n",
    "print('Tamaño predicción \"h_t\": ', h.shape)\n",
    "print('.'*50)\n",
    "print('Predicción (c_t): ', c)\n",
    "print('Tamaño predicción \"c_t\": ', c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Evul8UjJCyS"
   },
   "source": [
    "Es decir que en este caso tendremos:\n",
    "\n",
    "| *timestep* (entrada) | valor | $h_t$ | $c_t$ |\n",
    "|:--------------------:|:-----:|---------------------------------------|---------------------------------------|\n",
    "| 1                    | 0.5   | -------------                                   | -------------      |\n",
    "| 2                    | 0.4   | -------------                                   | -------------      |\n",
    "| 3                    | 0.3   | [0.04, -0.06, 0.03, -0.05, 0.02]      | [0.08, -0.12, 0.05, -0.11, 0.05]      |\n",
    "\n",
    "Esta opción es útil cuando procesamos secuencias relativamente largas y queremos preservar la memoria de largo plazo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DSMNdaOJKXr"
   },
   "source": [
    "## 5. Usando `return_sequences` y `return_state` simultáneamente\n",
    "\n",
    "Y finalmente podemos combinar `return_sequences=True` y `return_state=True` para retornar:\n",
    "\n",
    "- **Todos** los valores de la salida\n",
    "- El **último** estado oculto ($h_t$)\n",
    "- El **último** valor de la celda de estados ($c_t$):\n",
    "\n",
    "Veamos esta implementación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTzlsJfl8kbR",
    "outputId": "1d770854-764a-494e-c173-73f83e3de077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               [(None, 3, 5),            140       \n",
      "                              (None, 5),                         \n",
      "                              (None, 5)]                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 140 (560.00 Byte)\n",
      "Trainable params: 140 (560.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 1)\n",
      "Tamaño de salida: [(None, 3, 5), (None, 5), (None, 5)]\n",
      "----------------------------------------------------------------------\n",
      "Predicción (lstm_out):  [[[ 0.02129798 -0.04037673  0.02123253 -0.02901676  0.01275784]\n",
      "  [ 0.03483645 -0.0609595   0.02958979 -0.04655094  0.02243249]\n",
      "  [ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]]\n",
      "Tamaño predicción \"lstm_out\":  (1, 3, 5)\n",
      "..................................................\n",
      "Último estado oculto (h_t):  [[ 0.04174358 -0.06729254  0.03022056 -0.05514956  0.02848158]]\n",
      "Tamaño último estado oculto \"h_t\":  (1, 5)\n",
      "..................................................\n",
      "Último valor celda de estado (c_t):  [[ 0.08437636 -0.12790795  0.05566084 -0.11978056  0.05761085]]\n",
      "Tamaño último valor celda de estado \"c_t\":  (1, 5)\n"
     ]
    }
   ],
   "source": [
    "# Crear celda LSTM\n",
    "# - input_shape = 3x1\n",
    "# - units = 5\n",
    "# - return_sequences = True\n",
    "# - return_states = True\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,1))\n",
    "lstm_out, h, c = LSTM(5,\n",
    "                      return_sequences=True,\n",
    "                      return_state=True)(entrada) # Celda LSTM\n",
    "modelo = Model(inputs=entrada, outputs=[lstm_out, h, c])\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1))\n",
    "pred, h, c = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (lstm_out): ', pred)\n",
    "print('Tamaño predicción \"lstm_out\": ', pred.shape)\n",
    "print('.'*50)\n",
    "print('Último estado oculto (h_t): ', h)\n",
    "print('Tamaño último estado oculto \"h_t\": ', h.shape)\n",
    "print('.'*50)\n",
    "print('Último valor celda de estado (c_t): ', c)\n",
    "print('Tamaño último valor celda de estado \"c_t\": ', c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ktFF1d-4ldC"
   },
   "source": [
    "## 6. Celda LSTM + capa \"Dense\"\n",
    "\n",
    "Cuando queremos por ejemplo generar pronósticos sobre Series de Tiempo o clasificar una secuencia (por ejemplo en análisis de sentimientos) debemos añadir una capa de salida a la celda LSTM:\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1HCNWkAmn_o9QEv_IIzWpeSRs7oIbAYHm)\n",
    "\n",
    "Por ejemplo, si queremos generar pronósticos o generar texto a la salida, la capa `Dense` debe hacer una tarea de regresión (es decir debe predecir un número). En este caso la función de activación de `Dense` debe ser lineal.\n",
    "\n",
    "Por ejemplo, este sería el código para predecir un valor a futuro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSxe_Kkw9wz-",
    "outputId": "7e8e897d-361c-4b7b-c1cd-d8ee384eeab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 5)                 140       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 146 (584.00 Byte)\n",
      "Trainable params: 146 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 1)\n",
      "Tamaño de salida: (None, 1)\n",
      "----------------------------------------------------------------------\n",
      "Predicción (regresión):  [[-0.06192685]]\n",
      "Tamaño predicción:  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Crear celda LSTM:\n",
    "# - input_shape de 3x1\n",
    "# - units = 5\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
    "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
    "\n",
    "# Agregar capa de salida Dense\n",
    "salida = Dense(1)(lstm_out) # Capa de salida con 1 neurona y función de activación lineal\n",
    "modelo = Model(inputs=entrada, outputs=salida)\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
    "pred = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (regresión): ', pred)\n",
    "print('Tamaño predicción: ', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UNXhrvBI-MuQ"
   },
   "source": [
    "Y si queremos predecir múltiples valores simplemente añadimos el número de neuronas requerido a la capa \"Dense\".\n",
    "\n",
    "Por ejemplo, este sería el código para predecir 2 valores a futuro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXCPDs3x-X8X",
    "outputId": "cacf30ed-59c1-4431-82d6-ad33b8338848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 5)                 140       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 2)                 12        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 152 (608.00 Byte)\n",
      "Trainable params: 152 (608.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 1)\n",
      "Tamaño de salida: (None, 2)\n",
      "----------------------------------------------------------------------\n",
      "Predicción (regresión):  [[0.01347888 0.0076959 ]]\n",
      "Tamaño predicción:  (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Crear celda LSTM:\n",
    "# - input_shape de 3x1\n",
    "# - units = 5\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
    "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
    "\n",
    "\n",
    "# Agregar capa de salida Dense\n",
    "salida = Dense(2)(lstm_out) # Capa de salida con 2 neuronas y función de activación lineal\n",
    "modelo = Model(inputs=entrada, outputs=salida)\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
    "pred = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (regresión): ', pred)\n",
    "print('Tamaño predicción: ', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPxSkYFK-cof"
   },
   "source": [
    "Si queremos predecir una categoría podemos usar \"Dense\" pero con función de activación \"sigmoid\" (para máximo 2 categorías) o función de activación \"softmax\" (para 3 o más categorías).\n",
    "\n",
    "Por ejemplo, un clasificador de secuencias binario sería similar a este:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNExzmsh-oUH",
    "outputId": "fc1acb13-cbd8-461d-a599-caa4ba429518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 5)                 140       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 146 (584.00 Byte)\n",
      "Trainable params: 146 (584.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 1)\n",
      "Tamaño de salida: (None, 1)\n",
      "----------------------------------------------------------------------\n",
      "Predicción (clasificación binaria):  [[0.48452324]]\n",
      "Tamaño predicción:  (1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Crear celda LSTM:\n",
    "# - input_shape de 3x1\n",
    "# - units = 5\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
    "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
    "\n",
    "# Agregar capa de salida Dense para clasificación\n",
    "salida = Dense(1, activation='sigmoid')(lstm_out) # Capa de salida con 2 neuronas y función de activación sigmoidal\n",
    "modelo = Model(inputs=entrada, outputs=salida)\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
    "pred = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (clasificación binaria): ', pred)\n",
    "print('Tamaño predicción: ', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHJL5Gdk-2_J"
   },
   "source": [
    "Y este sería el código de ejemplo para un clasificador de secuencias con 4 categorías:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJLdmwUF-83-",
    "outputId": "ceeea73c-148e-4c8b-fc76-6d0655c2095c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información general del modelo: \n",
      "----------------------------------------------------------------------\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 3, 1)]            0         \n",
      "                                                                 \n",
      " lstm_10 (LSTM)              (None, 5)                 140       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4)                 24        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 164 (656.00 Byte)\n",
      "Trainable params: 164 (656.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "----------------------------------------------------------------------\n",
      "Tamaño entrada:  (None, 3, 1)\n",
      "Tamaño de salida: (None, 4)\n",
      "----------------------------------------------------------------------\n",
      "Predicción (clasificación multiclase):  [[0.26582992 0.25042662 0.22758336 0.25616005]]\n",
      "Tamaño predicción:  (1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Crear celda LSTM:\n",
    "# - input_shape de 3x1\n",
    "# - units = 5\n",
    "fijar_semillas()\n",
    "entrada = Input(shape=(3,1)) # (timesteps = 3) x (features = 1)\n",
    "lstm_out = LSTM(5)(entrada) # Celda LSTM con 5 unidades\n",
    "\n",
    "# Agregar capa de salida Dense para clasificación\n",
    "salida = Dense(4, activation='softmax')(lstm_out) # Capa de salida con 2 neuronas y función de activación sigmoidal\n",
    "modelo = Model(inputs=entrada, outputs=salida)\n",
    "\n",
    "# Imprimir información del modelo\n",
    "print('Información general del modelo: ')\n",
    "print('-'*70)\n",
    "print(modelo.summary())\n",
    "\n",
    "print('-'*70)\n",
    "print('Tamaño entrada: ', modelo.input_shape)\n",
    "print('Tamaño de salida:', modelo.output_shape)\n",
    "\n",
    "# Generar predicción e imprimir resultado en pantalla\n",
    "datos = np.array([0.5, 0.4, 0.3]).reshape((1,3,1)) # 1 dato con 3 timesteps y 1 feature\n",
    "pred = modelo.predict(datos, verbose=0)\n",
    "\n",
    "print('-'*70)\n",
    "print('Predicción (clasificación multiclase): ', pred)\n",
    "print('Tamaño predicción: ', pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HXd93BS6uBvA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
