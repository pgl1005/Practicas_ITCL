{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "432bb472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   encounter_id  patient_nbr             race  gender      age weight  \\\n",
      "0       2278392      8222157        Caucasian  Female   [0-10)      ?   \n",
      "1        149190     55629189        Caucasian  Female  [10-20)      ?   \n",
      "2         64410     86047875  AfricanAmerican  Female  [20-30)      ?   \n",
      "3        500364     82442376        Caucasian    Male  [30-40)      ?   \n",
      "4         16680     42519267        Caucasian    Male  [40-50)      ?   \n",
      "\n",
      "   admission_type_id  discharge_disposition_id  admission_source_id  \\\n",
      "0                  6                        25                    1   \n",
      "1                  1                         1                    7   \n",
      "2                  1                         1                    7   \n",
      "3                  1                         1                    7   \n",
      "4                  1                         1                    7   \n",
      "\n",
      "   time_in_hospital  ... citoglipton insulin  glyburide-metformin  \\\n",
      "0                 1  ...          No      No                   No   \n",
      "1                 3  ...          No      Up                   No   \n",
      "2                 2  ...          No      No                   No   \n",
      "3                 2  ...          No      Up                   No   \n",
      "4                 1  ...          No  Steady                   No   \n",
      "\n",
      "   glipizide-metformin  glimepiride-pioglitazone  metformin-rosiglitazone  \\\n",
      "0                   No                        No                       No   \n",
      "1                   No                        No                       No   \n",
      "2                   No                        No                       No   \n",
      "3                   No                        No                       No   \n",
      "4                   No                        No                       No   \n",
      "\n",
      "   metformin-pioglitazone  change diabetesMed readmitted  \n",
      "0                      No      No          No         NO  \n",
      "1                      No      Ch         Yes        >30  \n",
      "2                      No      No         Yes         NO  \n",
      "3                      No      Ch         Yes         NO  \n",
      "4                      No      Ch         Yes         NO  \n",
      "\n",
      "[5 rows x 50 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Data columns (total 50 columns):\n",
      " #   Column                    Non-Null Count   Dtype \n",
      "---  ------                    --------------   ----- \n",
      " 0   encounter_id              101766 non-null  int64 \n",
      " 1   patient_nbr               101766 non-null  int64 \n",
      " 2   race                      101766 non-null  object\n",
      " 3   gender                    101766 non-null  object\n",
      " 4   age                       101766 non-null  object\n",
      " 5   weight                    101766 non-null  object\n",
      " 6   admission_type_id         101766 non-null  int64 \n",
      " 7   discharge_disposition_id  101766 non-null  int64 \n",
      " 8   admission_source_id       101766 non-null  int64 \n",
      " 9   time_in_hospital          101766 non-null  int64 \n",
      " 10  payer_code                101766 non-null  object\n",
      " 11  medical_specialty         101766 non-null  object\n",
      " 12  num_lab_procedures        101766 non-null  int64 \n",
      " 13  num_procedures            101766 non-null  int64 \n",
      " 14  num_medications           101766 non-null  int64 \n",
      " 15  number_outpatient         101766 non-null  int64 \n",
      " 16  number_emergency          101766 non-null  int64 \n",
      " 17  number_inpatient          101766 non-null  int64 \n",
      " 18  diag_1                    101766 non-null  object\n",
      " 19  diag_2                    101766 non-null  object\n",
      " 20  diag_3                    101766 non-null  object\n",
      " 21  number_diagnoses          101766 non-null  int64 \n",
      " 22  max_glu_serum             101766 non-null  object\n",
      " 23  A1Cresult                 101766 non-null  object\n",
      " 24  metformin                 101766 non-null  object\n",
      " 25  repaglinide               101766 non-null  object\n",
      " 26  nateglinide               101766 non-null  object\n",
      " 27  chlorpropamide            101766 non-null  object\n",
      " 28  glimepiride               101766 non-null  object\n",
      " 29  acetohexamide             101766 non-null  object\n",
      " 30  glipizide                 101766 non-null  object\n",
      " 31  glyburide                 101766 non-null  object\n",
      " 32  tolbutamide               101766 non-null  object\n",
      " 33  pioglitazone              101766 non-null  object\n",
      " 34  rosiglitazone             101766 non-null  object\n",
      " 35  acarbose                  101766 non-null  object\n",
      " 36  miglitol                  101766 non-null  object\n",
      " 37  troglitazone              101766 non-null  object\n",
      " 38  tolazamide                101766 non-null  object\n",
      " 39  examide                   101766 non-null  object\n",
      " 40  citoglipton               101766 non-null  object\n",
      " 41  insulin                   101766 non-null  object\n",
      " 42  glyburide-metformin       101766 non-null  object\n",
      " 43  glipizide-metformin       101766 non-null  object\n",
      " 44  glimepiride-pioglitazone  101766 non-null  object\n",
      " 45  metformin-rosiglitazone   101766 non-null  object\n",
      " 46  metformin-pioglitazone    101766 non-null  object\n",
      " 47  change                    101766 non-null  object\n",
      " 48  diabetesMed               101766 non-null  object\n",
      " 49  readmitted                101766 non-null  object\n",
      "dtypes: int64(13), object(37)\n",
      "memory usage: 38.8+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('diabetic_data.csv')\n",
    "\n",
    "print(df.head())\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ef0f91",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma de X: (101766, 2465)\n",
      "Forma de y: (101766,)\n",
      "Número de columnas en X: 2465\n",
      "\n",
      "Información del DataFrame limpio:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101766 entries, 0 to 101765\n",
      "Columns: 2465 entries, encounter_id to diabetesMed_Yes\n",
      "dtypes: float64(13), uint8(2452)\n",
      "memory usage: 248.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Crear una copia del DataFrame original para trabajar\n",
    "df_copy = df.copy()\n",
    "\n",
    "# Reemplazar '?' por NaN en la copia\n",
    "df_copy.replace(\"?\", np.nan, inplace=True)\n",
    "\n",
    "# Verificar y limpiar la variable objetivo 'readmitted'\n",
    "if 'readmitted' in df_copy.columns:\n",
    "    y = df_copy['readmitted'].copy()\n",
    "    df_copy.drop(columns=['readmitted'], inplace=True)\n",
    "    y = y.apply(lambda x: 0 if x == 'NO' else 1)\n",
    "else:\n",
    "    raise ValueError(\"La columna 'readmitted' no se encontró en el DataFrame.\")\n",
    "\n",
    "# Convertir variables categóricas a variables dummy\n",
    "cat_cols = df_copy.select_dtypes(include=['object']).columns\n",
    "df_copy = pd.get_dummies(df_copy, columns=cat_cols)\n",
    "\n",
    "# Estandarizar variables numéricas\n",
    "num_cols = df_copy.select_dtypes(include=['int64', 'float64']).columns\n",
    "scaler = StandardScaler()\n",
    "df_copy[num_cols] = scaler.fit_transform(df_copy[num_cols])\n",
    "\n",
    "# Asignar X después de preprocesamiento\n",
    "X = df_copy\n",
    "\n",
    "# Guardar el DataFrame limpio en un nuevo archivo CSV\n",
    "#df_copy.to_csv('DiabetesLimpio.csv', index=False)\n",
    "\n",
    "# Verificar la forma y las columnas de X y y para asegurarnos de que todo esté correcto\n",
    "print(\"Forma de X:\", X.shape)\n",
    "print(\"Forma de y:\", y.shape)\n",
    "print(\"Número de columnas en X:\", len(X.columns))\n",
    "\n",
    "# Información sobre el DataFrame preprocesado\n",
    "print()\n",
    "print(\"Información del DataFrame limpio:\")\n",
    "print(df_copy.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6768f7fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos y sesgos antes del entrenamiento:\n",
      "Layer 0 weights:\n",
      "[[-1.7782612e-02  1.6994663e-03  4.2044688e-02 ...  3.3657428e-02\n",
      "   2.0636659e-02  2.6258003e-02]\n",
      " [ 1.7070446e-02 -3.0590205e-02  1.6307686e-02 ... -2.8216915e-02\n",
      "   4.2368259e-02  1.9513667e-03]\n",
      " [-3.3753216e-02  3.4142535e-02  1.0396037e-02 ... -3.8298782e-02\n",
      "   1.7113242e-02  1.0874223e-02]\n",
      " ...\n",
      " [ 4.3874983e-02  1.6085047e-02  2.0299185e-02 ... -2.7538681e-02\n",
      "  -2.1521002e-05 -1.3466179e-03]\n",
      " [-3.2429341e-02  1.9418631e-02  7.0847198e-04 ... -4.3750733e-02\n",
      "   2.6270907e-02 -4.1971169e-03]\n",
      " [-6.7501068e-03 -4.2376965e-02 -3.9947908e-02 ...  4.1013759e-02\n",
      "  -2.6290238e-02 -3.8821395e-02]]\n",
      "\n",
      "Layer 0 biases:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Layer 1 (Dropout) no tiene pesos ni bias.\n",
      "\n",
      "Layer 2 weights:\n",
      "[[ 0.0326023  -0.04802718  0.09111819 ...  0.10684279 -0.06181483\n",
      "   0.05090269]\n",
      " [-0.00585499  0.00912418 -0.0998261  ... -0.0566071   0.07837205\n",
      "  -0.01451681]\n",
      " [-0.05630506 -0.01935393  0.09965513 ... -0.00998653 -0.11287934\n",
      "   0.11935467]\n",
      " ...\n",
      " [ 0.04924468 -0.06906193  0.07785629 ...  0.066783    0.05099196\n",
      "   0.10660451]\n",
      " [ 0.00546209 -0.07264766  0.00482594 ...  0.10828642 -0.0672337\n",
      "  -0.07649863]\n",
      " [-0.10547621 -0.09055098 -0.05457465 ... -0.05825059 -0.09488355\n",
      "   0.00869534]]\n",
      "\n",
      "Layer 2 biases:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Layer 3 (Dropout) no tiene pesos ni bias.\n",
      "\n",
      "Layer 4 weights:\n",
      "[[ 0.09507768 -0.15421498 -0.07220303 ...  0.08210842  0.02929202\n",
      "   0.16791292]\n",
      " [ 0.03210194  0.17078824 -0.12304068 ...  0.06524163  0.16198121\n",
      "  -0.08984069]\n",
      " [-0.01653737 -0.12378399 -0.05505407 ... -0.10932391  0.03355154\n",
      "  -0.09959005]\n",
      " ...\n",
      " [ 0.02952497  0.15038998 -0.07076447 ...  0.01246905  0.08331405\n",
      "   0.08489652]\n",
      " [ 0.00103976  0.02910101 -0.01343144 ...  0.102194   -0.05132575\n",
      "   0.14218374]\n",
      " [-0.01465298  0.02386725  0.14117076 ...  0.15633668  0.09949999\n",
      "  -0.01924138]]\n",
      "\n",
      "Layer 4 biases:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Layer 5 (Dropout) no tiene pesos ni bias.\n",
      "\n",
      "Layer 6 weights:\n",
      "[[-0.04782915  0.13919175  0.13345265 ... -0.17227441  0.1928649\n",
      "   0.04025286]\n",
      " [-0.16280776 -0.1779936  -0.06483382 ... -0.21962559 -0.20943165\n",
      "   0.06714278]\n",
      " [-0.19790053 -0.21107388  0.0807718  ...  0.02958328  0.07681501\n",
      "   0.08278531]\n",
      " ...\n",
      " [ 0.07610005  0.1384781  -0.04857028 ... -0.07449043 -0.02142239\n",
      "   0.00851828]\n",
      " [-0.20566624  0.24860907  0.11418825 ... -0.04784298 -0.00039941\n",
      "  -0.15920186]\n",
      " [-0.21950817  0.07595354  0.14394546 ...  0.02015418  0.210253\n",
      "   0.21014565]]\n",
      "\n",
      "Layer 6 biases:\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "\n",
      "Layer 7 (Dropout) no tiene pesos ni bias.\n",
      "\n",
      "Layer 8 weights:\n",
      "[[-0.3806328 ]\n",
      " [ 0.4252618 ]\n",
      " [-0.10043803]\n",
      " [-0.366356  ]\n",
      " [-0.26593688]\n",
      " [-0.34823513]\n",
      " [ 0.05861834]\n",
      " [-0.29592198]\n",
      " [ 0.38850415]\n",
      " [ 0.25996727]\n",
      " [ 0.11338627]\n",
      " [-0.10512677]\n",
      " [-0.1656782 ]\n",
      " [-0.00783154]\n",
      " [ 0.02550974]\n",
      " [ 0.03246933]\n",
      " [-0.36188194]\n",
      " [-0.10641077]\n",
      " [-0.17474806]\n",
      " [-0.10453367]\n",
      " [-0.0020003 ]\n",
      " [-0.15540859]\n",
      " [-0.15455872]\n",
      " [ 0.42507207]\n",
      " [ 0.40638298]\n",
      " [-0.16986403]\n",
      " [ 0.06637147]\n",
      " [ 0.3832329 ]\n",
      " [ 0.24338704]\n",
      " [-0.11615628]\n",
      " [-0.36135328]\n",
      " [-0.29269552]]\n",
      "\n",
      "Layer 8 biases:\n",
      "[0.]\n",
      "\n",
      "Epoch 1/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.5448 - loss: 0.2567 - val_accuracy: 0.6276 - val_loss: 0.2281\n",
      "Epoch 2/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 13ms/step - accuracy: 0.6367 - loss: 0.2245 - val_accuracy: 0.6229 - val_loss: 0.2272\n",
      "Epoch 3/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6572 - loss: 0.2156 - val_accuracy: 0.6229 - val_loss: 0.2259\n",
      "Epoch 4/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6797 - loss: 0.2060 - val_accuracy: 0.6291 - val_loss: 0.2278\n",
      "Epoch 5/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.6897 - loss: 0.2015 - val_accuracy: 0.6291 - val_loss: 0.2293\n",
      "Epoch 6/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.6993 - loss: 0.1936 - val_accuracy: 0.6281 - val_loss: 0.2321\n",
      "Epoch 7/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7089 - loss: 0.1887 - val_accuracy: 0.6303 - val_loss: 0.2328\n",
      "Epoch 8/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7199 - loss: 0.1833 - val_accuracy: 0.6340 - val_loss: 0.2341\n",
      "Epoch 9/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7340 - loss: 0.1755 - val_accuracy: 0.6283 - val_loss: 0.2418\n",
      "Epoch 10/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7486 - loss: 0.1685 - val_accuracy: 0.6183 - val_loss: 0.2421\n",
      "Epoch 11/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7586 - loss: 0.1626 - val_accuracy: 0.6180 - val_loss: 0.2513\n",
      "Epoch 12/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.7734 - loss: 0.1544 - val_accuracy: 0.6126 - val_loss: 0.2531\n",
      "Epoch 13/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.7797 - loss: 0.1494 - val_accuracy: 0.6178 - val_loss: 0.2572\n",
      "Epoch 14/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.7934 - loss: 0.1411 - val_accuracy: 0.6215 - val_loss: 0.2600\n",
      "Epoch 15/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8065 - loss: 0.1347 - val_accuracy: 0.6089 - val_loss: 0.2627\n",
      "Epoch 16/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.8147 - loss: 0.1281 - val_accuracy: 0.6102 - val_loss: 0.2685\n",
      "Epoch 17/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 12ms/step - accuracy: 0.8223 - loss: 0.1266 - val_accuracy: 0.6070 - val_loss: 0.2710\n",
      "Epoch 18/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8322 - loss: 0.1194 - val_accuracy: 0.6075 - val_loss: 0.2776\n",
      "Epoch 19/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8376 - loss: 0.1161 - val_accuracy: 0.6028 - val_loss: 0.2797\n",
      "Epoch 20/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8454 - loss: 0.1116 - val_accuracy: 0.6050 - val_loss: 0.2833\n",
      "Epoch 21/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8546 - loss: 0.1067 - val_accuracy: 0.5994 - val_loss: 0.2846\n",
      "Epoch 22/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8645 - loss: 0.1008 - val_accuracy: 0.6038 - val_loss: 0.2898\n",
      "Epoch 23/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8632 - loss: 0.0990 - val_accuracy: 0.6038 - val_loss: 0.2939\n",
      "Epoch 24/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8674 - loss: 0.0975 - val_accuracy: 0.5996 - val_loss: 0.2906\n",
      "Epoch 25/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8759 - loss: 0.0926 - val_accuracy: 0.6092 - val_loss: 0.3010\n",
      "Epoch 26/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8784 - loss: 0.0910 - val_accuracy: 0.6050 - val_loss: 0.2985\n",
      "Epoch 27/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.8818 - loss: 0.0888 - val_accuracy: 0.5976 - val_loss: 0.3044\n",
      "Epoch 28/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8851 - loss: 0.0856 - val_accuracy: 0.5994 - val_loss: 0.3045\n",
      "Epoch 29/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8942 - loss: 0.0809 - val_accuracy: 0.5981 - val_loss: 0.2988\n",
      "Epoch 30/30\n",
      "\u001b[1m573/573\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.8922 - loss: 0.0817 - val_accuracy: 0.5984 - val_loss: 0.3066\n",
      "\n",
      "Precisión durante el entrenamiento:\n",
      "Precisión en el conjunto de entrenamiento:\n",
      "[57.08748698234558, 63.33833932876587, 65.59301018714905, 67.09703803062439, 68.28715801239014, 69.05691027641296, 70.3234612941742, 71.39893770217896, 72.8838562965393, 74.1203784942627, 75.03207325935364, 76.56339406967163, 77.50784754753113, 78.60515713691711, 79.99454140663147, 80.99631667137146, 81.64323568344116, 82.51398801803589, 83.14180374145508, 83.6768090724945, 84.73044633865356, 85.55206656455994, 85.62849760055542, 86.25085353851318, 87.14616894721985, 87.29903101921082, 87.60747909545898, 88.11519145965576, 88.62290382385254, 88.7320876121521]\n",
      "\n",
      "Precisión en el conjunto de validación:\n",
      "[62.760990858078, 62.29427456855774, 62.29427456855774, 62.90837526321411, 62.90837526321411, 62.81012296676636, 63.03119659423828, 63.39965462684631, 62.834686040878296, 61.827558279037476, 61.80299520492554, 61.26258969306946, 61.7784321308136, 62.14689016342163, 60.894131660461426, 61.01694703102112, 60.69761514663696, 60.74674725532532, 60.280030965805054, 60.50110459327698, 59.93613600730896, 60.37828326225281, 60.37828326225281, 59.9606990814209, 60.918694734573364, 60.50110459327698, 59.76418852806091, 59.93613600730896, 59.81331467628479, 59.83787775039673]\n",
      "\n",
      "Accuracy promedio en entrenamiento: 78.28%\n",
      "Accuracy promedio en validación: 61.32%\n",
      "\n",
      "Pesos y sesgos después del entrenamiento:\n",
      "Layer 0 weights:\n",
      "[[-0.05740403  0.3448669   0.24062271 ... -0.07873105  0.10733636\n",
      "   0.34813416]\n",
      " [-0.05045534 -0.16012864 -0.39442155 ... -0.26450413  0.605975\n",
      "  -0.03003808]\n",
      " [-0.12029198  0.22510405 -0.15511444 ... -0.07350744  0.21705377\n",
      "  -0.05131782]\n",
      " ...\n",
      " [-0.0811979  -0.02307492  0.13794835 ...  0.13995168 -0.20556478\n",
      "   0.16282263]\n",
      " [-0.02571601  0.01804022  0.17830472 ... -0.027104    0.12984121\n",
      "  -0.07359128]\n",
      " [-0.01346338 -0.04099839 -0.21754389 ...  0.02436689 -0.12986055\n",
      "   0.03057282]]\n",
      "\n",
      "Layer 0 biases:\n",
      "[-0.73072284 -0.42868912 -0.678346   -0.48334146 -0.7030648  -0.74764967\n",
      " -0.27863383 -0.42978755 -0.34931457 -0.35032308 -0.68231666 -0.51198107\n",
      " -0.5109562  -0.5862336  -0.6061901  -0.37299573 -0.41798416 -0.76694214\n",
      " -0.17205936 -0.7288458  -0.72587293 -0.48773208 -0.37475646 -0.40025812\n",
      " -0.5360918  -0.56471825 -0.6029458  -0.5762685  -0.44016156 -0.6902997\n",
      " -0.6375913  -0.5279465  -0.54844636 -0.57140946 -0.7498342  -0.58606774\n",
      " -0.4525742  -0.37911913 -0.6717705  -0.54124373 -0.6348033  -0.72290695\n",
      " -0.6396906  -0.27852258 -0.69760066 -0.45050746 -0.46040708 -0.5944036\n",
      " -0.61564195 -0.36585426 -0.5780396  -0.3133905  -0.54580754 -0.59768677\n",
      " -0.47494775 -0.42427668 -0.43639654 -0.48265827 -0.7092767  -0.494657\n",
      " -0.663874   -0.4784743  -0.6121519  -0.66792357 -0.40191862 -0.64112294\n",
      " -0.43421686 -0.55242926 -0.36766553 -0.4457902  -0.5348102  -0.285584\n",
      " -0.2918705  -0.5692449  -0.3817541  -0.3655085  -0.39685515 -0.21950884\n",
      " -0.3794001  -0.6011108  -0.334137   -0.40253064 -0.39444238 -0.6334614\n",
      " -0.3252704  -0.49907348 -0.63223386 -0.41103745 -0.63090426 -0.7102426\n",
      " -0.52311355 -0.4470762  -0.6294835  -0.60001487 -0.5642169  -0.53542304\n",
      " -0.4977227  -0.32062167 -0.4514605  -0.49732387 -0.7030529  -0.45410013\n",
      " -0.3606083  -0.3161859  -0.40917102 -0.41921496 -0.367553   -0.23779267\n",
      " -0.6644114  -0.54233146 -0.51818883 -0.61487854 -0.5797974  -0.54206765\n",
      " -0.5301546  -0.5999279  -0.61744714 -0.16482896 -0.5801583  -0.6553963\n",
      " -0.6449754  -0.1795593  -0.79494    -0.58104086 -0.49391007 -0.46516454\n",
      " -0.52717084 -0.4014861  -0.5964764  -0.5966721  -0.4658449  -0.4742192\n",
      " -0.5648433  -0.47903574 -0.5268377  -0.64909434 -0.7282673  -0.5677637\n",
      " -0.71592265 -0.48065433 -0.47413298 -0.4757578  -0.76433    -0.4946049\n",
      " -0.36288333 -0.49485326 -0.59224796 -0.65338504 -0.5683506  -0.3405805\n",
      " -0.4703016  -0.5609377  -0.63031524 -0.53674203 -0.5135973  -0.47987235\n",
      " -0.58744645 -0.73263884 -0.53525203 -0.5528598  -0.34739822 -0.76736355\n",
      " -0.6445522  -0.5591621  -0.6400994  -0.4597201  -0.5968391  -0.64008176\n",
      " -0.6302223  -0.25582254 -0.75362873 -0.7432972  -0.40896446 -0.5220443\n",
      " -0.5645043  -0.75266665 -0.46421134 -0.47080824 -0.551836   -0.5982074\n",
      " -0.67996097 -0.4884621  -0.4815857  -0.55397815 -0.70926255 -0.6699566\n",
      " -0.3104353  -0.44002405 -0.3083127  -0.3122386  -0.29116812 -0.60729414\n",
      " -0.5762422  -0.5629499  -0.5648625  -0.4023819  -0.42635924 -0.67951536\n",
      " -0.5027378  -0.4200556  -0.41781166 -0.74910873 -0.4094179  -0.46562025\n",
      " -0.59332293 -0.3015369  -0.4939728  -0.522789   -0.60496235 -0.53707963\n",
      " -0.57155555 -0.45593613 -0.74116194 -0.38720503 -0.53968513 -0.46628538\n",
      " -0.428752   -0.547162   -0.3138433  -0.6434681  -0.46957222 -0.34692338\n",
      " -0.48185024 -0.44963202 -0.43974617 -0.08236439 -0.5657596  -0.65408885\n",
      " -0.63298804 -0.39098105 -0.6427163  -0.25224766 -0.5114167  -0.5611187\n",
      " -0.6727283  -0.64144474 -0.61155254 -0.6741657  -0.38928816 -0.676299\n",
      " -0.6765917  -0.62827665 -0.53191423 -0.5412857  -0.63299704 -0.5270546\n",
      " -0.7337464  -0.5614145  -0.5500846  -0.4798174  -0.4946206  -0.4645222\n",
      " -0.14933781 -0.56278497 -0.4855273  -0.56780386 -0.35669044 -0.27246845]\n",
      "\n",
      "Layer 1 (Dropout) no tiene pesos ni bias.\n",
      "\n",
      "Layer 2 weights:\n",
      "[[ 0.10215604 -0.2720492  -0.05177788 ...  0.13108163 -0.14223412\n",
      "   0.04603417]\n",
      " [-0.04320621 -0.03295288 -0.1717809  ...  0.00649246  0.23651507\n",
      "  -0.0909384 ]\n",
      " [-0.08777975  0.14375699  0.19116278 ... -0.16306546 -0.0859504\n",
      "   0.12813929]\n",
      " ...\n",
      " [ 0.08066701 -0.16908935  0.08153787 ...  0.01123834 -0.02346422\n",
      "   0.01835743]\n",
      " [-0.23144925 -0.23748541  0.10162203 ...  0.16849655 -0.26827195\n",
      "  -0.11921123]\n",
      " [ 0.00879409 -0.11269099 -0.22789867 ... -0.41433644 -0.18105333\n",
      "   0.10172608]]\n",
      "\n",
      "Layer 2 biases:\n",
      "[ 0.01178659 -0.00788043  0.16270237  0.02063026  0.23719     0.03641528\n",
      " -0.12595704 -0.19606543 -0.08646862  0.05147716  0.18605065 -0.41758084\n",
      " -0.06736238 -0.08553991  0.25100756  0.0452492   0.00280604  0.02382798\n",
      " -0.07443619  0.08877051  0.00118186  0.21668026 -0.06595542 -0.24954848\n",
      " -0.02464764  0.05767449 -0.09798173 -0.25194842  0.31786478 -0.2739136\n",
      " -0.310993   -0.01336987 -0.07453584  0.2584202  -0.38244897 -0.07640447\n",
      "  0.05270554  0.02848018 -0.07240525 -0.09298543 -0.1610676   0.07869612\n",
      "  0.10638636 -0.0662149  -0.14474617 -0.05064632 -0.56052953 -0.0937527\n",
      " -0.20156644  0.00319112 -0.08810324  0.11641208 -0.10065496  0.12266339\n",
      "  0.14110671 -0.10609993  0.04794233  0.239727   -0.33041036 -0.29664794\n",
      " -0.07471484 -0.03036765  0.10530473 -0.24086268  0.04987529 -0.03851216\n",
      " -0.03182742  0.2264127   0.14468768  0.00491266  0.03856578 -0.03473326\n",
      "  0.11051136  0.11296141  0.29535422 -0.07155579 -0.13819714  0.03677261\n",
      "  0.18949917 -0.03168413 -0.25948122  0.16173987 -0.12422463  0.01649452\n",
      "  0.01526089 -0.3273672   0.19793884 -0.0687657   0.26912042 -0.12338702\n",
      " -0.13242711  0.01847162  0.09646995 -0.10853894 -0.01131878 -0.08345652\n",
      " -0.03319871 -0.25391445 -0.34008378 -0.1133127   0.07897113 -0.00809917\n",
      "  0.01254844 -0.22378053  0.08510263 -0.04330497 -0.02121514  0.15681747\n",
      " -0.0476741   0.01319123  0.258151   -0.07784008  0.05156958  0.05877855\n",
      "  0.32646793  0.14203882  0.27759743 -0.06602122  0.06220047  0.21175182\n",
      "  0.3998788  -0.16192654  0.03967986  0.12327708 -0.04404688  0.09375688\n",
      " -0.13568929 -0.11819328]\n",
      "\n",
      "Layer 3 (Dropout) no tiene pesos ni bias.\n",
      "\n",
      "Layer 4 weights:\n",
      "[[-0.03071675 -0.24913274 -0.18974867 ...  0.11661331  0.04715136\n",
      "   0.09909937]\n",
      " [ 0.13168573  0.15920165 -0.17195237 ...  0.0487425  -0.01162031\n",
      "  -0.12937382]\n",
      " [ 0.00108806 -0.07726795  0.06435093 ... -0.10453247  0.02617268\n",
      "  -0.04913065]\n",
      " ...\n",
      " [-0.13581942  0.12202406 -0.15857899 ... -0.2450587  -0.02008544\n",
      "  -0.12020101]\n",
      " [-0.04995737 -0.17995732  0.20473193 ...  0.10140669 -0.19602238\n",
      "   0.03506589]\n",
      " [-0.17655015 -0.05724135  0.00969048 ...  0.00027957  0.07405953\n",
      "   0.04644075]]\n",
      "\n",
      "Layer 4 biases:\n",
      "[-0.07550178 -0.29959902  0.36093745  0.44864774  0.1947618   0.41240236\n",
      " -0.06049559 -0.10038127 -0.02437171 -0.215612    0.47133148 -0.18355198\n",
      "  0.49630678 -0.03931646  0.03905698 -0.11253262  0.07763604 -0.23914081\n",
      " -0.24408814 -0.28150174  0.16261421  0.2134893   0.03136363  0.12292253\n",
      "  0.5942037  -0.00556306  0.552104    0.4025336   0.10683849  0.18276764\n",
      " -0.36284146  0.12483649  0.39855868  0.13973795 -0.01385988  0.3556267\n",
      "  0.0936197  -0.34285668  0.4110716   0.38153124  0.4241169   0.30892792\n",
      "  0.3029814  -0.05789228  0.13381977  0.39862397  0.41978738 -0.20768298\n",
      "  0.4450422  -0.12779471 -0.26419804  0.08387501 -0.22902179 -0.3198191\n",
      "  0.45397007  0.3786702   0.11463125 -0.20809664 -0.1762418   0.09618916\n",
      " -0.07373008  0.3571663   0.39021623  0.40943673]\n",
      "\n",
      "Layer 5 (Dropout) no tiene pesos ni bias.\n",
      "\n",
      "Layer 6 weights:\n",
      "[[-0.06797204  0.26931655  0.00715382 ... -0.15797317  0.0676986\n",
      "  -0.1086759 ]\n",
      " [-0.0449838  -0.20487659  0.09344099 ... -0.03800195 -0.10110652\n",
      "   0.03477577]\n",
      " [-0.35377747 -0.08574531 -0.32812348 ... -0.20635995  0.1021094\n",
      "  -0.04498168]\n",
      " ...\n",
      " [-0.14092883  0.23473541 -0.14767672 ... -0.1482139  -0.1932466\n",
      "  -0.04184332]\n",
      " [-0.2650977   0.25319478 -0.12422263 ... -0.3254073  -0.03740242\n",
      "  -0.5075494 ]\n",
      " [-0.31992176  0.14589065  0.0213961  ... -0.24485774 -0.04991082\n",
      "   0.12566599]]\n",
      "\n",
      "Layer 6 biases:\n",
      "[ 0.22652748  0.34397084  0.4101966   0.31848043  0.00912     0.36007667\n",
      "  0.5831744  -0.06542578  0.43159243  0.47074333  0.5469707   0.30116656\n",
      "  0.15287453  0.41820273  0.45005777  0.66728616  0.34627846  0.523244\n",
      "  0.38423458  0.5506572   0.42574805  0.31905362  0.46028158  0.44474703\n",
      "  0.301587    0.38061616  0.39176244  0.3474183   0.46406582  0.42263034\n",
      "  0.26150787  0.39443222]\n",
      "\n",
      "Layer 7 (Dropout) no tiene pesos ni bias.\n",
      "\n",
      "Layer 8 weights:\n",
      "[[-0.0791401 ]\n",
      " [ 0.07935349]\n",
      " [-0.07682455]\n",
      " [-0.05662441]\n",
      " [-0.09793723]\n",
      " [-0.02734548]\n",
      " [ 0.05907116]\n",
      " [ 0.05343072]\n",
      " [ 0.0653783 ]\n",
      " [ 0.06167103]\n",
      " [ 0.03522227]\n",
      " [-0.06433598]\n",
      " [-0.04497504]\n",
      " [-0.03787523]\n",
      " [ 0.03747891]\n",
      " [ 0.06290726]\n",
      " [-0.06962585]\n",
      " [-0.0544538 ]\n",
      " [-0.06572706]\n",
      " [-0.05374172]\n",
      " [-0.0458849 ]\n",
      " [-0.05301223]\n",
      " [-0.06909006]\n",
      " [ 0.07645112]\n",
      " [ 0.07009319]\n",
      " [-0.03900415]\n",
      " [ 0.04197063]\n",
      " [ 0.04747541]\n",
      " [ 0.06744578]\n",
      " [-0.04061604]\n",
      " [-0.05442466]\n",
      " [-0.04526975]]\n",
      "\n",
      "Layer 8 biases:\n",
      "[0.02660263]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_subset = X.iloc[50883:, :]\n",
    "y_subset = y.iloc[50883:]\n",
    "\n",
    "# Dividir en conjunto de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_subset,y_subset, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizar los datos de entrada\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Inicializar el modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Añadir capas densas\n",
    "model.add(Dense(258, activation='relu', input_shape=(X_train_scaled.shape[1],)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation='relu'))  \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(32, activation='relu'))  \n",
    "model.add(Dropout(0.3)) \n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compilar el modelo\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Función para obtener y mostrar pesos y sesgos\n",
    "def print_layer_weights(model):\n",
    "    for i, layer in enumerate(model.layers):\n",
    "        weights = layer.get_weights()\n",
    "        if len(weights) > 0: \n",
    "            weights, biases = weights\n",
    "            print(f\"Layer {i} weights:\\n{weights}\\n\")\n",
    "            print(f\"Layer {i} biases:\\n{biases}\\n\")\n",
    "        else:\n",
    "            print(f\"Layer {i} ({layer.__class__.__name__}) no tiene pesos ni bias.\\n\")\n",
    "\n",
    "\n",
    "# Mostrar pesos y sesgos antes del entrenamiento\n",
    "print(\"Pesos y sesgos antes del entrenamiento:\")\n",
    "print_layer_weights(model)\n",
    "\n",
    "# Entrenar el modelo\n",
    "parametrosModelo = model.fit(X_train_scaled, y_train, epochs=30, batch_size=64, validation_split=0.1)\n",
    "\n",
    "# Mostrar precisión después del entrenamiento\n",
    "print()\n",
    "print(\"Precisión durante el entrenamiento:\")\n",
    "print(\"Precisión en el conjunto de entrenamiento:\")\n",
    "print([acc * 100 for acc in parametrosModelo.history['accuracy']])\n",
    "print()\n",
    "print(\"Precisión en el conjunto de validación:\")\n",
    "print([acc * 100 for acc in parametrosModelo.history['val_accuracy']]) \n",
    "\n",
    "# Calcular accuracy promedio\n",
    "avg_accuracy_train = np.mean(parametrosModelo.history['accuracy']) * 100\n",
    "avg_accuracy_val = np.mean(parametrosModelo.history['val_accuracy']) * 100\n",
    "\n",
    "print()\n",
    "print(f\"Accuracy promedio en entrenamiento: {avg_accuracy_train:.2f}%\")\n",
    "print(f\"Accuracy promedio en validación: {avg_accuracy_val:.2f}%\")\n",
    "\n",
    "# Mostrar pesos y sesgos después del entrenamiento\n",
    "print()\n",
    "print(\"Pesos y sesgos después del entrenamiento:\")\n",
    "print_layer_weights(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51fcd04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6115 - loss: 0.3047\n",
      "Loss en el conjunto de prueba: 0.30572623014450073\n",
      "Accuracy en el conjunto de prueba: 0.6082342267036438\n",
      "\u001b[1m319/319\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Matriz de Confusión:\n",
      "[[3504 2043]\n",
      " [1944 2686]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.64      5547\n",
      "           1       0.57      0.58      0.57      4630\n",
      "\n",
      "    accuracy                           0.61     10177\n",
      "   macro avg       0.61      0.61      0.61     10177\n",
      "weighted avg       0.61      0.61      0.61     10177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f\"Loss en el conjunto de prueba: {test_loss}\")\n",
    "print(f\"Accuracy en el conjunto de prueba: {test_accuracy}\")\n",
    "\n",
    "# Hacer predicciones\n",
    "predictions = model.predict(X_test_scaled)\n",
    "predicted_classes = (predictions > 0.5).astype(\"int32\")\n",
    "\n",
    "# Evaluar métricas adicionales\n",
    "print(\"Matriz de Confusión:\")\n",
    "print(confusion_matrix(y_test, predicted_classes))\n",
    "\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a1a62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
